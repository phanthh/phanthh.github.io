{"pageProps":{"post":{"title":"Surveillance Capitalism: An Overview","publishedAt":"2021-06-07","summary":"An overview of Shoshana Zuboff's Surveillance Capitalism.","image":"/images/surveillance-capitalism-overview/banner.png","body":{"raw":"\n<Image\n  alt={`Surveillance Capitalism: An Overview`}\n  src={`/images/surveillance-capitalism-overview/banner.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\n_This was my final essay of CS-E5480: Digital Ethics D. [PDF](/static/surveillance-capitalism-overview.pdf)_\n\n## Introduction\n\nThe 21st century witnessed the rapid digital transformation of the political,\nsocioeconomic landscape made possible by the internet. Digital technology was\nadvancing at a pace no one had expected, engendered waves of transformation\nacross multiple industries. As the burning flame of industrial innovation slowly\ndied out, the imminent information revolution was on the horizon, waiting to be\nset ablaze.\n\nThe first decade was remembered as the rise of the first tech companies: Google,\nApple and Microsoft all experienced unprecedented growth during the period.\nThese accomplishments were celebrated globally, mostly in the US, as new\nconsumer products and digital services bring many conveniences and life\nimprovements. Little do we know that during the same period, a group of\nindividuals had invented an exploitative totalitarian form of capitalism, an\nunprecedented event of the digital transformation. Years later did the world\nstart to realize the nature of these big tech companies and the practices they\nemployed. Many research papers were published to address antitrust laws and\nmonopolistic practices of these companies but little addressed the fundamental\neconomic systems that comprise all their operations. Zuboff was first to realize\nand coined the term \"surveillance capitalism\" to characterize this rogue\neconomic system. This essay aims to provide an overview of the foundation of\nsurveillance capitalism, its components, operations, consequences, and a simple\npath for exploration of the topic.\n\n## Outline\n\nSurveillance capitalism as a general economical concept was introduced in \"A\ndigital declaration\" by Shoshana Zuboff in 2014. The paper marks the first\npublication on this mutation of capitalism and sparks many discussions on many\ntechnical practices of Big Tech companies such as Google, Facebook, and\nMicrosoft. Subsequent scholarly articles further built upon the definition that\nhad already been laid out in her original paper. In 2019, a major work on\nsurveillance capitalism was published: \"The Age of Surveillance Capitalism: The\nFight for a Human Future at the New Frontier of Power\" (@shoshanazuboffAgeSurveillanceCapitalism2019), in which, she\nsummarized:\n\n> \"Surveillance capitalism is best described as a coup from above, not an\n> overthrow of the state but rather an overthrow of the people's sovereignty and a\n> prominent force in the perilous drift towards democratic deconsolidation that\n> now threatens Western liberal democracies.\"(@shoshanazuboffAgeSurveillanceCapitalism2019)\n\nThese ominous consequences of surveillance capitalism call for a coherent\nethical framework in an attempt to encapsulate all of its complications. In this\nessay, I suggest one such framework, albeit simplified, which consists of three\ndistinct but interconnected operations that constitute the primary behaviors\nobserved in surveillance capitalism:\n\n- The mining of \"behavioral surplus\" from user activities and experiences.\n  (extraction)\n- The feeding of behavioral data into advanced analytical processes\n  (\"machine intelligence\") to produce \"prediction products\" (manufacture)\n- The exchange of prediction products on \"behavioral futures markets\"\n  (commercialization)\n\nConcrete examples will be shown in subsequent sections, where the three primary\noperations of surveillance capitalism are laid out and explored in detail.\nHowever, it is necessary that some fundamental theoretical concepts are clearly\nunderstood beforehand.\n\n## Extraction and Manufacture\n\n### Machine Intelligence\n\nFirst, to understand the extraction and manufacturing process of surveillance\ncapitalism, it is necessary that a frequently used term is clearly understood\nbeforehand: machine intelligence. The term is used frequently in Zuboff’s \"Age\nof surveillance capitalism\" as a means to bypass the technicality of analytical\npractices (@shoshanazuboffAgeSurveillanceCapitalism2019). In summary, machine intelligence is a\ngeneralization of different specialized computational tools that are used for\ndata analysis and manufacture of data-based products. It is used frequently as\nan umbrella phrase that covers complex computational methods employed by\nsurveillance capitalists such as artificial intelligence, predictive analytics,\nand machine learning, allowing for easy reference in other areas of science. Its\nrole is to help concentrate our attention on the more important issues of\nsurveillance capitalism, decentering our focus from the technology it employs to\nits objectives instead.\n\n### The Behavioral Value Reinvestment Cycle\n\n<Image\n  alt={`The Behavioral Value Reinvestment Cycle`}\n  src={`/images/surveillance-capitalism-overview/cycle.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nA fundamental component of surveillance capitalism is the loop of behavioral\ndata collection, analysis, services improvements and increased user activities -\nthe behavioral value reinvestment cycle. It came to existence during the early\ninvention of surveillance capitalism at Google, when engineers began to apply\nmachine intelligence to massive collections of user’s past queries. The outputs\nof these analyses were then translated to improvements of the user experiences:\nbetter detection of typos, better accuracy and more relevance query\nresults/suggestions. In other words, the value created was reinvested directly\ninto improving the user experience, hence the name. These enhancements in turn\nattract more users onto the platform, producing even more behavioral data for\nanalysis. This self-improving mechanism is so effective that only 1 year since\nGoogle's establishment, more than seven million user requests were conducted on\nits search engine each day. Note that user data was provided at no cost but so\nare the enhancements of the platform’s services for users.\n\nBefore moving on, there are some misconceptions that need to be pointed out.\nSince there is no economic exchange, no price and no profit, it is inaccurate to\nthink of Google’s users as the customers. There are also no wages involved or\nthe provision of the means of production: users are not paid for the data they\nproduced nor do they operate the process of web crawling or its enhancements.\nConsequently, it is also wrong to think of them as workers of the cycle.\nFinally, there is also a common rhetoric that the user is the \"product\" of the\nsystem. However, this is also misleading as many aspects of being the \"product\"\nare missing and such expressions further confuse the issue rather than\nclarifying it.\n\nThe cycle was once all there is to the operations of Google - the first\npractitioner of surveillance capitalism. While being different to previous\ncustomer-manufacture relationships by embodying a new mechanism for improving\nproducts and enlarging user base, the behavioral reinvestment cycle is not yet\ncapitalism, at least in its current stage.\n\n<Image\n  alt={`Google HQ`}\n  src={`/images/surveillance-capitalism-overview/google-hq.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nDuring the early days of Google, there was the major issue of converting the\nservice usages to revenues: charging the user for their searches seemed\nfinancially risky and counterproductive; monetizing the searches seemed to be a\ndangerous precedent as much of Google's indexed information is taken without\npayment from the contents’ hosts. The cycle, while possessing the capacity of\nproducing advanced technologies, is financially unsustainable and failed as a\nfunctional business model. For Google, providing advertisement service was the\nonly viable solution.\n\nThe decision of incorporating advertisements on the company website faced much\nopposition at the start, mostly from the company's engineers and analysts. Many\nengineers of Google's AdWords team displayed antipathy toward ads, fearing\nuncontrolled bias towards advertisers could steer the company away from user’s\nneed and degrading searches’ integrity (@brinAnatomyLargescaleHypertextual1998). However,\nfinancial pressure from the fallout of the \"dotcom bubble\" and intense market\ncompetition in the early 2000s eventually surmounted ethical ideals. To make\nmore money, it was proposed that advertisements should be automatically targeted\nto specific consumers, simplifying the whole process of picking which keywords\ninciting which ads for advertisers wanting to use Google online advertising\nplatform. Finding the solution to this problem eventually led to Google’s\ndiscovery of the centerpiece of surveillance capitalism: the behavioral surplus.\n\n### Behavioral Surplus\n\n<Image\n  alt={`The discovery of behavioral surplus`}\n  src={`/images/surveillance-capitalism-overview/surplus.png`}\n  width={1280}\n  height={1000}\n  priority\n/>\n\nThe behavior surplus can be described as by-products formed from user digital\nactivities, usually existing in the form of behavioral patterns in collection of\nuser data, readily extracted and transformed into prediction products. It is a\ncomponent of the behavioral value reinvestment cycle, the \"data exhaust\"\nproduced during user digital activities and their analysis (@cukierDataDataEverywhere)\n. For example, the innocent act of searching the web for a keyword on Google\nproduces a wake of collateral data such as search counts, phrasing, tonations,\nclick patterns, dwell times and geographic locations. These excess behavioral\ndata were once thought to be \"exhaust material\" and devoid of meaningful values,\nthus, were either cached in massive data stores as backups or discarded\nentirely. For instance, Google stores user queries results for archiving\npurposes in its early days of operation without much knowledge of its hidden\npredictive values.\n\nLater analysis of such seemingly unrelated accidental data in massive quantities\nor \"data mining\" reveals behavioral patterns representing sensitive aspects of\nhuman behaviors such as emotions, moods, intentions and needs. Such insights\ngive Google a powerful competitive advantage over its competitors in the ads\nservices provider market. For example, a rival search startup Overture had\ndeveloped an online auction system to address the scaling problem of online\ntargeted advertisement. Compelled, Google also developed a similar auction\nsystem but added a transformational functionality: probabilistic modeling of\nuser’s clicks on ads. The model produced a numeric representation that can be\nused to compare the effectiveness of advertiser’s ads on a particular user, not\nonly maximizing specificity and accuracy but also the number of advertisers\nGoogle's can handle at any given time by minimizing. Eventually, Google\nsucceeded and held the monopoly over web searching, eliminating many companies\nin the same service space during the process. (@coySecretGoogleSuccess2006)\n\nThe discovery of behavioral surplus and its capability of behavioral prediction\nmarked the shift of priorities for Google’s investment strategy. Under the hood,\nthe behavioral reinvestment cycle was rapidly subordinated by a much more\ncomplex system of operations unbeknown to users. While some of the data relevant\nto the improvement of user services will still be reinvested for the benefit of\nthe consumer, the focus was now placed on the maximization of extracted\nbehavioral data and development of machine intelligence and operations that\nderive values from these data. The purpose of improving services slowly\ndescended to keeping users engaged and the platform reliable for the intention\nof extraction. For Google, it is keeping users reliant on Google for online\nbrowsing and analyzing their queries for better targeted ads. Note that targeted\nadvertisement is just one of the derivatives of prediction products made\npossible by surveillance capitalism and not the only source of values for\nsurveillance capitalists.\n\nThe discovery had also induced another change in corporate mindset at Google:\nthe company is now compelled to actively hunt for sources of behavioral surplus\nand better tools of extraction rather than waiting for accidental patterns\nemerging from user activities. This was characterized by Zuboff as the\nextraction imperative, in contrast to the production imperative of industrial\ncapitalism. An example is Google’s \"senseless\" \\$1.65 billion acquisition of\nYoutube at a time this video-sharing startup was ridden with copyright\ninfringement lawsuits and a year of profitless operation. Another example is\nFacebook’s \"reckless\" purchase of overvalued unprofitable startups such as the\nvirtual reality company Oculus (\\$2 billion) and the messaging platform WhatApps\n(\\$19 billion). Only years later was it known that these seemingly ludicrous\nbusiness decisions were deliberately aimed at acquiring potential sources of\nbehavioral surplus that evidently, had brought tremendous amounts of capital for\nthese first movers of surveillance capitalism.\n\n### The Moat\n\n<Image\n  alt={`The discovery of behavioral surplus`}\n  src={`/images/surveillance-capitalism-overview/moat.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nIn the discussion of \"The moat around the castle\" (@shoshanazuboffAgeSurveillanceCapitalism2019) Zuboff\nlaid out three main paths of exploration that go into detail how socio-political\ncircumstances and deliberate practices of surveillance capitalism obfuscate its\nemployers’ practices and legitimizing their exploitative operations. These\nincludes: (1) the pursuit and defense of corporate freedom and operational\nrights in unregulated space; (2) the sudden federal interests in the\ncapabilities of behavioral surplus analytics after 9/11; and (3) the\nconstruction of fortifications in politic and academia to protect and deflect\nscrutiny of its practices.\n\n#### Right to Unregulated Space\n\nThe founders at Google had instituted a corporate structure that allowed the two\nopposites to coexist: total controls over the market sphere and the pursuit of\nfreedom in the public sphere. Such freedom was made possible by the unregulated\nnature of cyberspace, mostly due to its novelty as an area of business\nactivities and economic operations. The cyberspace was characterized by Eric\nSchmidt and Jared Cohen in the book \"The New Digital Age\", as the world's\n\"largest ungovern space\" and truly unbound by \"terrestrial laws\" and\njurisdictions (@ericschmidtNewDigitalAge2013). The lack of political institutions is what\nmade cyberspace attractive to surveillance capitalists: a frictionless space\nwhere behavioral surplus extraction and manufacturing operations are done\nsmoothly and efficiently without any socio-political hindrances. Such policy\ngaps were a direct transformation of the speed gaps between democratic\ninstitutions and bigtech corporations. As admitted by Schmidt in his elaboration\nof the 2011 senate testimony, the same antidemocratic measure of leveraging\nspeed \"also work for Google\" and described as:\n\n> \"This is an Andy Grove (Intel former CEO) formula.... \"High tech runs\n> three-times faster than normal businesses. And the government runs three-times\n> slower than normal businesses. So we have a nine-times gap.... And so what you\n> want to do is you want to make sure that the government does not get in the way\n> and slow things down\"\n\n#### A Historical Circumstance\n\nThe 9/11 terror attacks had caused significant mentality changes among\ngovernment officials and the general sentiments toward public surveillance. The\nhistorical circumstance has united the causes of public intelligence agencies\nand the early surveillance capitalist Google, producing a unique historical\ndeformity: surveillance exceptionalism.\n\nThe terror attacks had shifted the perception of the federal government on the\npractices of online surveillance: from being operations in violation of user\nprivacy to mission necessities critical to the safety of the public. Both\ninstitutions coveted certainty of user behaviors and were motivated to fulfill\nthat craving in their respective domains at any cost. The circumstances lent\nsurveillance capitalism a shelter from scrutiny by slowly legitimizing its\noperations in the political sphere. Intelligence agencies were now motivated to\nreplicate Google’s means of extraction and manufacture, spreading surveillance\ncapitalism’s ideologies to other sectors of power in society. For example, in\n2006, General Keith Alexander outlined his vision for a search tool called\nICREACH that, quoted: \"allow unprecedented volumes of metadata to be shared and\nanalyzed across the many agencies in the Intelligence\nCommunity\"(@gallagherSurveillanceEngineHow2014). In 2007 two NSA analysts wrote an\ninternal training manual on how to find information on the internet\n(@bishopNSARevealsIts2013). Such craving slowly translated to reliance, as the\ngovernment grew dependent on Silicon Valley to defend security threats looming\nin cyberspace, deepening the relationship between governments and surveillance\ncapitalists.\n\n#### Fortification\n\nThe fortification strategies employed by surveillance capitalists, to my\nknowledge, consist of four main demonstrative operations: providing competitive\nadvantage in electoral politics, personnel migration to and from government\nsectors, aggressive lobbying and manipulating public perception by influencing\ncultural conversation and academic publications. For example, the 2008 Obama\npresidential campaign had Eric Schmidt - the sitting CEO of Google - as one of\nthe main directors, in charge of implementing state-of-the-art data strategies\nthat have the potential to shadow traditional political campaigning with the\nscience of behavioral prediction (@EricSchmidtObama2016). Personnel\nmigration can be seen frequently through the years of operation at Google: the\nGoogle Transparency Project found that by April 2016, 61 individuals had\nmigrated from the Google Sphere (company employees plus affiliates and\nlaw/lobbying firms) to the government and over 197 government officials had\nmoved back (@GoogleTransparencyReport). Lobbying is a common practice for Google: in\n2014, more than \\$17 million was spent on lobbying outlay and in 2018, that\nnumber rose to more than \\$18 million (@GoogleTransparencyReport). To obfuscate its\npractices, Google exercises information manipulation by means of financial\npressure to influence academic research and steering public opinion. Since 2009,\nit has been reported that Google had deliberately sought out and funded\nuniversity professors for policy papers in agreement with Google's positions.\n(@nicasPayingProfessorsGoogle2017)\n\n### A Human Invention\n\n<Image\n  alt={`Human invention`}\n  src={`/images/surveillance-capitalism-overview/invention.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nIt is important to emphasize that surveillance capitalism is an intentional\ncreation, an invention made at a specific time and at a specific place by a\ngroup of individuals. It is not an inevitable result of the digital\ntransformation, nor an expression of information capitalism. It was deliberately\nconstructed to solve a business problem at a particular moment in history. If\nthere was no recession nor the dotcom crash, or the people in charge making the\ndecision that they had made, the fire might not have started and surveillance\ncapitalism might have not come to existence.\n\nMany elements of online surveillance predated the creation of surveillance. For\nexample, \"cookies\" or small pieces of data stored on the user's computer by the\nweb browser that allow websites to remember user information and activities, had\nalready been introduced in 1994 by Netscape (@kristolHTTPCookiesStandards2001). Other\nsimilar online browsing trackers and surveillance tools such as \"web beacon\" or\n\"web bugs\" were well-known among experts during the late 1990s\n(@smithWebBugFaq1999). However, it was Google that integrated a wide range of\nonline surveillance mechanisms, from cookies to predictive analytics that allow\nfor the institution of a new logic of accumulation by means of data extraction\nand analysis, establishing a new market for commercialized prediction products\nwhere customers are businesses, not consumers.\n\n## Commercialization\n\n### Prediction Product\n\n<Image\n  alt={`Prediction product`}\n  src={`/images/surveillance-capitalism-overview/product.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nSurveillance capitalism is a derivative of capitalism and thus the exchange of\nproducts among its actors is one of its fundamental activities. Differ from\npopular industrial capitalism where commodities are manufactured goods traded on\nthe open market, surveillance capitalism goods are prediction products that\nforecast future behaviors of users. These include, but not limited to: thoughts,\nactions, emotions, moods, desires, physical needs, psychological needs,\nshort-term intentions and possibly long-term intentions, given sufficiently\npowerful behavioral data. It is the nature of prediction products that explains\nwhy Google constantly distant themselves from the notion of selling personal\ndata. Google does not sell the raw materials, they sell the predictions. The\nclaim of privacy purity is just a superficial excuse that conceal the backstage\noperations of surveillance capitalism it employs.\n\nPrediction products reduce uncertainty in their customers' operations, advising\nthem where and when to allocate resources. The quality of prediction products is\na direct translation of its accuracy: how good are their approximations of\nreality. The more precise the prediction, the lower the risk and the higher the\nrevenue. For the fledgling company Google, targeted advertisements are the\nembodiment of prediction products. However, as demonstrated by Zuboff,\nadvertising is far from being the end of the commodification of behavioral data.\n\n### Behavioral Market\n\n<Image\n  alt={`Behavioral Market`}\n  src={`/images/surveillance-capitalism-overview/market.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nPrediction products after being fabricated by machine intelligence from massive\ncollections of behavioral surplus are then sold on a new kind of market: the\nbehavioral futures market. The market exchanges exclusively the knowledge of\nfuture behaviors of consumers. Although for most of the history of surveillance\ncapitalism, the dominant players of this new marketplace are advertisers, there\nis no reason why such markets are limited to this particular group.\n\nThe scope of behavioral futures markets has expanded throughout the advance of\nsurveillance capitalism in modern society, both in terms of potential customers\nand the variety of traded products: once confined to the online targeted\nadvertisement services, products of surveillance capitalists now may comprise\noffline predictions of users locations, emotions and actions, automated tools\nthat generated those predictions, and ultimately, behavioral modification tools\nthat align user behavior to the business’s means of profit-making. While\nsurveillance capitalism is based on classical capitalism and shares many common\ndynamics in its commercialization, there are necessary distinctions between the\ntwo that are worth highlighting.\n\nThe classical producer-consumer relationship of capitalism is starkly different\nfrom this freshly formed variance of it. On one hand, classical capitalism\nallows for constructive relations between the manufacturers and the consumers,\nin which the former creates supply and the latter induces demand. Manufacturers\nbase their course of actions on the state of the consumer market, adjusting\nproduct price, quality and capacity of their factories accordingly while for\nmost consumers, purchase decisions are based on the final price tags, affected\nprimarily by the original prices set by manufacturers.\n\nIn contrast, surveillance capitalism relationships with consumers - the users\nof the services - are exploitative rather than constructive. The consumers of\ndigital services have little to no influence on the operations of these\nservices. More and more of our online activities are accompanied by machine\nintelligence beyond our understanding. In fact, they have become behavioral\nmodification tools that are purposely designed to herd consumers like sheep to\nareas of data extraction. For example, Youtube video recommendation algorithms\nare programmed to maximize user on-site time rather than satisfying user needs\n(@bishopAnxietyPanicSelfoptimization2018). Another example is the clips sharing platform TikTok\nwith its personalized machine learning contents that keep young users hooked for\nhours (@andersonGettingAcquaintedSocial2020). Essentially, surveillance capitalists are\ntrying to automate consumers' behaviors, stripping their decision rights.\nConsumers on the other hand, have little to no power over their operations.\ntransformative effects on uncontrolled advancement of surveillance capitalism\nwill be discussed in detail in the next section.\n\nThis void of power over our own digital experience is what made the behavioral\nvalue reinvestment loop to run smoothly and the manufacture of prediction\nproducts run efficiently. Opposite to information capitalism, the services\nprovided by surveillance capitalists are nothing but hooks that lure users into\nconvenient areas of extraction. We are far from being the end consumer of\nsurveillance capitalism, in reality, we are on the opposite ends: the raw\nmaterials, objects of an inescapable system of continuous extraction.\n\n## Instrumentarian Power\n\n<Image\n  alt={`Behavioral automation`}\n  src={`/images/surveillance-capitalism-overview/automated.png`}\n  width={1280}\n  height={720}\n  priority\n/>\n\nCompetition in any capitalistic economic system drives the innovation of the\nmeans of production. However, in future rendition of surveillance capitalism,\ninnovations may not be required to equal more efficient manufacturing tools and\nextraction. Zuboff suspected that future surveillance capitalists could discover\nthat the best way to maximize their competitive advantages is to automate our\nbehaviors directly. Rather than produce more accurate algorithms and better\ntools of extractions, they may modify user behaviors and align them according to\ntheir customers' needs instead, maximizing the effectiveness of their no longer\nprediction product but behavioral modifications. As portrayed in her words:\n\n> \" With this reorientation from knowledge to power, it is no longer enough to\n> automate information flows about us; the goal now is to automate\n> us.\"(@shoshanazuboffAgeSurveillanceCapitalism2019)\n\nThis realization among future surveillance capitalists might mark the birth of a\nnew species of power: instrumentarianism. The means of manufacture in\nsurveillance capitalism is now replaced by means of behavioral modification.\nPlayers of the system are now stuck in a continuous loop of intensification of\nthe mean behavioral controls, enjoying the gathering might of instrumentarian\npower that these means endowed.\n\nMoreover, the means of behavioral modification may not be limited to the digital\nworld. Competitive dynamics might nudge the expansion of behavioral futures\nmarkets beyond the digital sphere and into the physical world. The same\nfoundational mechanism used to lure and guide your online activities and\ndecisions such as liking posts, picking a product in an online webstore and\nwatching a particular Youtube video, can be repurposed to physically modifying\nyour behavior in the real world. For example Pokemon Go was Google's first\npublicly known experiment of physical behavioral modification in the real world\n(@shoshanazuboffAgeSurveillanceCapitalism2019). The viral phenomenon attracts millions of users across\nthe globe and becomes a tremendous financial success for Niantic Lab -\nsurprising to most, is an internal startup at Google - but most importantly for\nGoogle, it is a proof that such expansion of surveillance capitalism into the\nmarket of real-world behavioral modification is possible.\n\n## Conclusion\n\nIn the essay, I proposed a framework for exploration of surveillance capitalism\nand its relevant discussions. Starting from the fundamental operations of\nextraction and manufacture, we explored the concept of behavioral surplus and\nthe cycle that generates them: the behavioral reinvestment cycle. Then, we\nwitnessed how the inventor and first partitioner of surveillance capitalism:\nGoogle, came up with the solution to the financial problem they faced and the\neventual logical steps that they took to reach the invention of surveillance\ncapitalism. We also explored how different aspects of surveillance capitalists\nare protected and obfuscated and its nature as a man made creation. Finally we\nmoved on to the discussion of the commercial aspect of surveillance capitalism:\nprediction products and its market for exchange and consumption. We end our\nessay with a small discussion of the advancement of surveillance capitalism and\nits elevation from prediction products to behavioral modification as the primary\nmeans of production.\n\n## Reference\n","code":"var Component=(()=>{var h=Object.create;var r=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var p=(t,a)=>()=>(a||t((a={exports:{}}).exports,a),a.exports),g=(t,a)=>{for(var o in a)r(t,o,{get:a[o],enumerable:!0})},s=(t,a,o,n)=>{if(a&&typeof a==\"object\"||typeof a==\"function\")for(let i of u(a))!m.call(t,i)&&i!==o&&r(t,i,{get:()=>a[i],enumerable:!(n=d(a,i))||n.enumerable});return t};var b=(t,a,o)=>(o=t!=null?h(f(t)):{},s(a||!t||!t.__esModule?r(o,\"default\",{value:t,enumerable:!0}):o,t)),v=t=>s(r({},\"__esModule\",{value:!0}),t);var l=p((G,c)=>{c.exports=_jsx_runtime});var T={};g(T,{default:()=>k,frontmatter:()=>y});var e=b(l()),y={title:\"Surveillance Capitalism: An Overview\",publishedAt:\"2021-06-07\",summary:\"An overview of Shoshana Zuboff's Surveillance Capitalism.\",image:\"/images/surveillance-capitalism-overview/banner.png\"};function w(t={}){let{wrapper:a}=t.components||{};return a?(0,e.jsx)(a,Object.assign({},t,{children:(0,e.jsx)(o,{})})):o();function o(){let n=Object.assign({p:\"p\",em:\"em\",a:\"a\",h2:\"h2\",span:\"span\",sup:\"sup\",blockquote:\"blockquote\",ul:\"ul\",li:\"li\",h3:\"h3\",h4:\"h4\",section:\"section\",ol:\"ol\"},t.components),{Image:i}=n;return i||x(\"Image\",!0),(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(i,{alt:\"Surveillance Capitalism: An Overview\",src:\"/images/surveillance-capitalism-overview/banner.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsxs)(n.em,{children:[\"This was my final essay of CS-E5480: Digital Ethics D. \",(0,e.jsx)(n.a,{href:\"/static/surveillance-capitalism-overview.pdf\",children:\"PDF\"})]})}),`\n`,(0,e.jsxs)(n.h2,{id:\"introduction\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#introduction\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Introduction\"]}),`\n`,(0,e.jsx)(n.p,{children:`The 21st century witnessed the rapid digital transformation of the political,\nsocioeconomic landscape made possible by the internet. Digital technology was\nadvancing at a pace no one had expected, engendered waves of transformation\nacross multiple industries. As the burning flame of industrial innovation slowly\ndied out, the imminent information revolution was on the horizon, waiting to be\nset ablaze.`}),`\n`,(0,e.jsx)(n.p,{children:`The first decade was remembered as the rise of the first tech companies: Google,\nApple and Microsoft all experienced unprecedented growth during the period.\nThese accomplishments were celebrated globally, mostly in the US, as new\nconsumer products and digital services bring many conveniences and life\nimprovements. Little do we know that during the same period, a group of\nindividuals had invented an exploitative totalitarian form of capitalism, an\nunprecedented event of the digital transformation. Years later did the world\nstart to realize the nature of these big tech companies and the practices they\nemployed. Many research papers were published to address antitrust laws and\nmonopolistic practices of these companies but little addressed the fundamental\neconomic systems that comprise all their operations. Zuboff was first to realize\nand coined the term \"surveillance capitalism\" to characterize this rogue\neconomic system. This essay aims to provide an overview of the foundation of\nsurveillance capitalism, its components, operations, consequences, and a simple\npath for exploration of the topic.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"outline\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#outline\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Outline\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`Surveillance capitalism as a general economical concept was introduced in \"A\ndigital declaration\" by Shoshana Zuboff in 2014. The paper marks the first\npublication on this mutation of capitalism and sparks many discussions on many\ntechnical practices of Big Tech companies such as Google, Facebook, and\nMicrosoft. Subsequent scholarly articles further built upon the definition that\nhad already been laid out in her original paper. In 2019, a major work on\nsurveillance capitalism was published: \"The Age of Surveillance Capitalism: The\nFight for a Human Future at the New Frontier of Power\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),`, in which, she\nsummarized:`]}),`\n`,(0,e.jsxs)(n.blockquote,{children:[`\n`,(0,e.jsxs)(n.p,{children:[`\"Surveillance capitalism is best described as a coup from above, not an\noverthrow of the state but rather an overthrow of the people's sovereignty and a\nprominent force in the perilous drift towards democratic deconsolidation that\nnow threatens Western liberal democracies.\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-2\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})})]}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:`These ominous consequences of surveillance capitalism call for a coherent\nethical framework in an attempt to encapsulate all of its complications. In this\nessay, I suggest one such framework, albeit simplified, which consists of three\ndistinct but interconnected operations that constitute the primary behaviors\nobserved in surveillance capitalism:`}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:`The mining of \"behavioral surplus\" from user activities and experiences.\n(extraction)`}),`\n`,(0,e.jsx)(n.li,{children:`The feeding of behavioral data into advanced analytical processes\n(\"machine intelligence\") to produce \"prediction products\" (manufacture)`}),`\n`,(0,e.jsx)(n.li,{children:`The exchange of prediction products on \"behavioral futures markets\"\n(commercialization)`}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:`Concrete examples will be shown in subsequent sections, where the three primary\noperations of surveillance capitalism are laid out and explored in detail.\nHowever, it is necessary that some fundamental theoretical concepts are clearly\nunderstood beforehand.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"extraction-and-manufacture\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#extraction-and-manufacture\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Extraction and Manufacture\"]}),`\n`,(0,e.jsxs)(n.h3,{id:\"machine-intelligence\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#machine-intelligence\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Machine Intelligence\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`First, to understand the extraction and manufacturing process of surveillance\ncapitalism, it is necessary that a frequently used term is clearly understood\nbeforehand: machine intelligence. The term is used frequently in Zuboff\\u2019s \"Age\nof surveillance capitalism\" as a means to bypass the technicality of analytical\npractices`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-3\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),`. In summary, machine intelligence is a\ngeneralization of different specialized computational tools that are used for\ndata analysis and manufacture of data-based products. It is used frequently as\nan umbrella phrase that covers complex computational methods employed by\nsurveillance capitalists such as artificial intelligence, predictive analytics,\nand machine learning, allowing for easy reference in other areas of science. Its\nrole is to help concentrate our attention on the more important issues of\nsurveillance capitalism, decentering our focus from the technology it employs to\nits objectives instead.`]}),`\n`,(0,e.jsxs)(n.h3,{id:\"the-behavioral-value-reinvestment-cycle\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#the-behavioral-value-reinvestment-cycle\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"The Behavioral Value Reinvestment Cycle\"]}),`\n`,(0,e.jsx)(i,{alt:\"The Behavioral Value Reinvestment Cycle\",src:\"/images/surveillance-capitalism-overview/cycle.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`A fundamental component of surveillance capitalism is the loop of behavioral\ndata collection, analysis, services improvements and increased user activities -\nthe behavioral value reinvestment cycle. It came to existence during the early\ninvention of surveillance capitalism at Google, when engineers began to apply\nmachine intelligence to massive collections of user\\u2019s past queries. The outputs\nof these analyses were then translated to improvements of the user experiences:\nbetter detection of typos, better accuracy and more relevance query\nresults/suggestions. In other words, the value created was reinvested directly\ninto improving the user experience, hence the name. These enhancements in turn\nattract more users onto the platform, producing even more behavioral data for\nanalysis. This self-improving mechanism is so effective that only 1 year since\nGoogle's establishment, more than seven million user requests were conducted on\nits search engine each day. Note that user data was provided at no cost but so\nare the enhancements of the platform\\u2019s services for users.`}),`\n`,(0,e.jsx)(n.p,{children:`Before moving on, there are some misconceptions that need to be pointed out.\nSince there is no economic exchange, no price and no profit, it is inaccurate to\nthink of Google\\u2019s users as the customers. There are also no wages involved or\nthe provision of the means of production: users are not paid for the data they\nproduced nor do they operate the process of web crawling or its enhancements.\nConsequently, it is also wrong to think of them as workers of the cycle.\nFinally, there is also a common rhetoric that the user is the \"product\" of the\nsystem. However, this is also misleading as many aspects of being the \"product\"\nare missing and such expressions further confuse the issue rather than\nclarifying it.`}),`\n`,(0,e.jsx)(n.p,{children:`The cycle was once all there is to the operations of Google - the first\npractitioner of surveillance capitalism. While being different to previous\ncustomer-manufacture relationships by embodying a new mechanism for improving\nproducts and enlarging user base, the behavioral reinvestment cycle is not yet\ncapitalism, at least in its current stage.`}),`\n`,(0,e.jsx)(i,{alt:\"Google HQ\",src:\"/images/surveillance-capitalism-overview/google-hq.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`During the early days of Google, there was the major issue of converting the\nservice usages to revenues: charging the user for their searches seemed\nfinancially risky and counterproductive; monetizing the searches seemed to be a\ndangerous precedent as much of Google's indexed information is taken without\npayment from the contents\\u2019 hosts. The cycle, while possessing the capacity of\nproducing advanced technologies, is financially unsustainable and failed as a\nfunctional business model. For Google, providing advertisement service was the\nonly viable solution.`}),`\n`,(0,e.jsxs)(n.p,{children:[`The decision of incorporating advertisements on the company website faced much\nopposition at the start, mostly from the company's engineers and analysts. Many\nengineers of Google's AdWords team displayed antipathy toward ads, fearing\nuncontrolled bias towards advertisers could steer the company away from user\\u2019s\nneed and degrading searches\\u2019 integrity`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-2\",id:\"user-content-fnref-2\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"2\"})}),`. However,\nfinancial pressure from the fallout of the \"dotcom bubble\" and intense market\ncompetition in the early 2000s eventually surmounted ethical ideals. To make\nmore money, it was proposed that advertisements should be automatically targeted\nto specific consumers, simplifying the whole process of picking which keywords\ninciting which ads for advertisers wanting to use Google online advertising\nplatform. Finding the solution to this problem eventually led to Google\\u2019s\ndiscovery of the centerpiece of surveillance capitalism: the behavioral surplus.`]}),`\n`,(0,e.jsxs)(n.h3,{id:\"behavioral-surplus\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#behavioral-surplus\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Behavioral Surplus\"]}),`\n`,(0,e.jsx)(i,{alt:\"The discovery of behavioral surplus\",src:\"/images/surveillance-capitalism-overview/surplus.png\",width:1280,height:1e3,priority:!0}),`\n`,(0,e.jsxs)(n.p,{children:[`The behavior surplus can be described as by-products formed from user digital\nactivities, usually existing in the form of behavioral patterns in collection of\nuser data, readily extracted and transformed into prediction products. It is a\ncomponent of the behavioral value reinvestment cycle, the \"data exhaust\"\nproduced during user digital activities and their analysis`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-3\",id:\"user-content-fnref-3\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"3\"})}),`\n. For example, the innocent act of searching the web for a keyword on Google\nproduces a wake of collateral data such as search counts, phrasing, tonations,\nclick patterns, dwell times and geographic locations. These excess behavioral\ndata were once thought to be \"exhaust material\" and devoid of meaningful values,\nthus, were either cached in massive data stores as backups or discarded\nentirely. For instance, Google stores user queries results for archiving\npurposes in its early days of operation without much knowledge of its hidden\npredictive values.`]}),`\n`,(0,e.jsxs)(n.p,{children:[`Later analysis of such seemingly unrelated accidental data in massive quantities\nor \"data mining\" reveals behavioral patterns representing sensitive aspects of\nhuman behaviors such as emotions, moods, intentions and needs. Such insights\ngive Google a powerful competitive advantage over its competitors in the ads\nservices provider market. For example, a rival search startup Overture had\ndeveloped an online auction system to address the scaling problem of online\ntargeted advertisement. Compelled, Google also developed a similar auction\nsystem but added a transformational functionality: probabilistic modeling of\nuser\\u2019s clicks on ads. The model produced a numeric representation that can be\nused to compare the effectiveness of advertiser\\u2019s ads on a particular user, not\nonly maximizing specificity and accuracy but also the number of advertisers\nGoogle's can handle at any given time by minimizing. Eventually, Google\nsucceeded and held the monopoly over web searching, eliminating many companies\nin the same service space during the process.`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-4\",id:\"user-content-fnref-4\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"4\"})})]}),`\n`,(0,e.jsx)(n.p,{children:`The discovery of behavioral surplus and its capability of behavioral prediction\nmarked the shift of priorities for Google\\u2019s investment strategy. Under the hood,\nthe behavioral reinvestment cycle was rapidly subordinated by a much more\ncomplex system of operations unbeknown to users. While some of the data relevant\nto the improvement of user services will still be reinvested for the benefit of\nthe consumer, the focus was now placed on the maximization of extracted\nbehavioral data and development of machine intelligence and operations that\nderive values from these data. The purpose of improving services slowly\ndescended to keeping users engaged and the platform reliable for the intention\nof extraction. For Google, it is keeping users reliant on Google for online\nbrowsing and analyzing their queries for better targeted ads. Note that targeted\nadvertisement is just one of the derivatives of prediction products made\npossible by surveillance capitalism and not the only source of values for\nsurveillance capitalists.`}),`\n`,(0,e.jsx)(n.p,{children:`The discovery had also induced another change in corporate mindset at Google:\nthe company is now compelled to actively hunt for sources of behavioral surplus\nand better tools of extraction rather than waiting for accidental patterns\nemerging from user activities. This was characterized by Zuboff as the\nextraction imperative, in contrast to the production imperative of industrial\ncapitalism. An example is Google\\u2019s \"senseless\" $1.65 billion acquisition of\nYoutube at a time this video-sharing startup was ridden with copyright\ninfringement lawsuits and a year of profitless operation. Another example is\nFacebook\\u2019s \"reckless\" purchase of overvalued unprofitable startups such as the\nvirtual reality company Oculus ($2 billion) and the messaging platform WhatApps\n($19 billion). Only years later was it known that these seemingly ludicrous\nbusiness decisions were deliberately aimed at acquiring potential sources of\nbehavioral surplus that evidently, had brought tremendous amounts of capital for\nthese first movers of surveillance capitalism.`}),`\n`,(0,e.jsxs)(n.h3,{id:\"the-moat\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#the-moat\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"The Moat\"]}),`\n`,(0,e.jsx)(i,{alt:\"The discovery of behavioral surplus\",src:\"/images/surveillance-capitalism-overview/moat.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsxs)(n.p,{children:['In the discussion of \"The moat around the castle\"',(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-4\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),` Zuboff\nlaid out three main paths of exploration that go into detail how socio-political\ncircumstances and deliberate practices of surveillance capitalism obfuscate its\nemployers\\u2019 practices and legitimizing their exploitative operations. These\nincludes: (1) the pursuit and defense of corporate freedom and operational\nrights in unregulated space; (2) the sudden federal interests in the\ncapabilities of behavioral surplus analytics after 9/11; and (3) the\nconstruction of fortifications in politic and academia to protect and deflect\nscrutiny of its practices.`]}),`\n`,(0,e.jsxs)(n.h4,{id:\"right-to-unregulated-space\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#right-to-unregulated-space\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Right to Unregulated Space\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`The founders at Google had instituted a corporate structure that allowed the two\nopposites to coexist: total controls over the market sphere and the pursuit of\nfreedom in the public sphere. Such freedom was made possible by the unregulated\nnature of cyberspace, mostly due to its novelty as an area of business\nactivities and economic operations. The cyberspace was characterized by Eric\nSchmidt and Jared Cohen in the book \"The New Digital Age\", as the world's\n\"largest ungovern space\" and truly unbound by \"terrestrial laws\" and\njurisdictions`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-5\",id:\"user-content-fnref-5\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"5\"})}),`. The lack of political institutions is what\nmade cyberspace attractive to surveillance capitalists: a frictionless space\nwhere behavioral surplus extraction and manufacturing operations are done\nsmoothly and efficiently without any socio-political hindrances. Such policy\ngaps were a direct transformation of the speed gaps between democratic\ninstitutions and bigtech corporations. As admitted by Schmidt in his elaboration\nof the 2011 senate testimony, the same antidemocratic measure of leveraging\nspeed \"also work for Google\" and described as:`]}),`\n`,(0,e.jsxs)(n.blockquote,{children:[`\n`,(0,e.jsx)(n.p,{children:`\"This is an Andy Grove (Intel former CEO) formula.... \"High tech runs\nthree-times faster than normal businesses. And the government runs three-times\nslower than normal businesses. So we have a nine-times gap.... And so what you\nwant to do is you want to make sure that the government does not get in the way\nand slow things down\"`}),`\n`]}),`\n`,(0,e.jsxs)(n.h4,{id:\"a-historical-circumstance\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#a-historical-circumstance\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"A Historical Circumstance\"]}),`\n`,(0,e.jsx)(n.p,{children:`The 9/11 terror attacks had caused significant mentality changes among\ngovernment officials and the general sentiments toward public surveillance. The\nhistorical circumstance has united the causes of public intelligence agencies\nand the early surveillance capitalist Google, producing a unique historical\ndeformity: surveillance exceptionalism.`}),`\n`,(0,e.jsxs)(n.p,{children:[`The terror attacks had shifted the perception of the federal government on the\npractices of online surveillance: from being operations in violation of user\nprivacy to mission necessities critical to the safety of the public. Both\ninstitutions coveted certainty of user behaviors and were motivated to fulfill\nthat craving in their respective domains at any cost. The circumstances lent\nsurveillance capitalism a shelter from scrutiny by slowly legitimizing its\noperations in the political sphere. Intelligence agencies were now motivated to\nreplicate Google\\u2019s means of extraction and manufacture, spreading surveillance\ncapitalism\\u2019s ideologies to other sectors of power in society. For example, in\n2006, General Keith Alexander outlined his vision for a search tool called\nICREACH that, quoted: \"allow unprecedented volumes of metadata to be shared and\nanalyzed across the many agencies in the Intelligence\nCommunity\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-6\",id:\"user-content-fnref-6\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"6\"})}),`. In 2007 two NSA analysts wrote an\ninternal training manual on how to find information on the internet`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-7\",id:\"user-content-fnref-7\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"7\"})}),`. Such craving slowly translated to reliance, as the\ngovernment grew dependent on Silicon Valley to defend security threats looming\nin cyberspace, deepening the relationship between governments and surveillance\ncapitalists.`]}),`\n`,(0,e.jsxs)(n.h4,{id:\"fortification\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#fortification\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Fortification\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`The fortification strategies employed by surveillance capitalists, to my\nknowledge, consist of four main demonstrative operations: providing competitive\nadvantage in electoral politics, personnel migration to and from government\nsectors, aggressive lobbying and manipulating public perception by influencing\ncultural conversation and academic publications. For example, the 2008 Obama\npresidential campaign had Eric Schmidt - the sitting CEO of Google - as one of\nthe main directors, in charge of implementing state-of-the-art data strategies\nthat have the potential to shadow traditional political campaigning with the\nscience of behavioral prediction`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-8\",id:\"user-content-fnref-8\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"8\"})}),`. Personnel\nmigration can be seen frequently through the years of operation at Google: the\nGoogle Transparency Project found that by April 2016, 61 individuals had\nmigrated from the Google Sphere (company employees plus affiliates and\nlaw/lobbying firms) to the government and over 197 government officials had\nmoved back`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-9\",id:\"user-content-fnref-9\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"9\"})}),`. Lobbying is a common practice for Google: in\n2014, more than $17 million was spent on lobbying outlay and in 2018, that\nnumber rose to more than $18 million`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-9\",id:\"user-content-fnref-9-2\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"9\"})}),`. To obfuscate its\npractices, Google exercises information manipulation by means of financial\npressure to influence academic research and steering public opinion. Since 2009,\nit has been reported that Google had deliberately sought out and funded\nuniversity professors for policy papers in agreement with Google's positions.`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-10\",id:\"user-content-fnref-10\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"10\"})})]}),`\n`,(0,e.jsxs)(n.h3,{id:\"a-human-invention\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#a-human-invention\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"A Human Invention\"]}),`\n`,(0,e.jsx)(i,{alt:\"Human invention\",src:\"/images/surveillance-capitalism-overview/invention.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`It is important to emphasize that surveillance capitalism is an intentional\ncreation, an invention made at a specific time and at a specific place by a\ngroup of individuals. It is not an inevitable result of the digital\ntransformation, nor an expression of information capitalism. It was deliberately\nconstructed to solve a business problem at a particular moment in history. If\nthere was no recession nor the dotcom crash, or the people in charge making the\ndecision that they had made, the fire might not have started and surveillance\ncapitalism might have not come to existence.`}),`\n`,(0,e.jsxs)(n.p,{children:[`Many elements of online surveillance predated the creation of surveillance. For\nexample, \"cookies\" or small pieces of data stored on the user's computer by the\nweb browser that allow websites to remember user information and activities, had\nalready been introduced in 1994 by Netscape`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-11\",id:\"user-content-fnref-11\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"11\"})}),`. Other\nsimilar online browsing trackers and surveillance tools such as \"web beacon\" or\n\"web bugs\" were well-known among experts during the late 1990s`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-12\",id:\"user-content-fnref-12\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"12\"})}),`. However, it was Google that integrated a wide range of\nonline surveillance mechanisms, from cookies to predictive analytics that allow\nfor the institution of a new logic of accumulation by means of data extraction\nand analysis, establishing a new market for commercialized prediction products\nwhere customers are businesses, not consumers.`]}),`\n`,(0,e.jsxs)(n.h2,{id:\"commercialization\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#commercialization\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Commercialization\"]}),`\n`,(0,e.jsxs)(n.h3,{id:\"prediction-product\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#prediction-product\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Prediction Product\"]}),`\n`,(0,e.jsx)(i,{alt:\"Prediction product\",src:\"/images/surveillance-capitalism-overview/product.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`Surveillance capitalism is a derivative of capitalism and thus the exchange of\nproducts among its actors is one of its fundamental activities. Differ from\npopular industrial capitalism where commodities are manufactured goods traded on\nthe open market, surveillance capitalism goods are prediction products that\nforecast future behaviors of users. These include, but not limited to: thoughts,\nactions, emotions, moods, desires, physical needs, psychological needs,\nshort-term intentions and possibly long-term intentions, given sufficiently\npowerful behavioral data. It is the nature of prediction products that explains\nwhy Google constantly distant themselves from the notion of selling personal\ndata. Google does not sell the raw materials, they sell the predictions. The\nclaim of privacy purity is just a superficial excuse that conceal the backstage\noperations of surveillance capitalism it employs.`}),`\n`,(0,e.jsx)(n.p,{children:`Prediction products reduce uncertainty in their customers' operations, advising\nthem where and when to allocate resources. The quality of prediction products is\na direct translation of its accuracy: how good are their approximations of\nreality. The more precise the prediction, the lower the risk and the higher the\nrevenue. For the fledgling company Google, targeted advertisements are the\nembodiment of prediction products. However, as demonstrated by Zuboff,\nadvertising is far from being the end of the commodification of behavioral data.`}),`\n`,(0,e.jsxs)(n.h3,{id:\"behavioral-market\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#behavioral-market\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Behavioral Market\"]}),`\n`,(0,e.jsx)(i,{alt:\"Behavioral Market\",src:\"/images/surveillance-capitalism-overview/market.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`Prediction products after being fabricated by machine intelligence from massive\ncollections of behavioral surplus are then sold on a new kind of market: the\nbehavioral futures market. The market exchanges exclusively the knowledge of\nfuture behaviors of consumers. Although for most of the history of surveillance\ncapitalism, the dominant players of this new marketplace are advertisers, there\nis no reason why such markets are limited to this particular group.`}),`\n`,(0,e.jsx)(n.p,{children:`The scope of behavioral futures markets has expanded throughout the advance of\nsurveillance capitalism in modern society, both in terms of potential customers\nand the variety of traded products: once confined to the online targeted\nadvertisement services, products of surveillance capitalists now may comprise\noffline predictions of users locations, emotions and actions, automated tools\nthat generated those predictions, and ultimately, behavioral modification tools\nthat align user behavior to the business\\u2019s means of profit-making. While\nsurveillance capitalism is based on classical capitalism and shares many common\ndynamics in its commercialization, there are necessary distinctions between the\ntwo that are worth highlighting.`}),`\n`,(0,e.jsx)(n.p,{children:`The classical producer-consumer relationship of capitalism is starkly different\nfrom this freshly formed variance of it. On one hand, classical capitalism\nallows for constructive relations between the manufacturers and the consumers,\nin which the former creates supply and the latter induces demand. Manufacturers\nbase their course of actions on the state of the consumer market, adjusting\nproduct price, quality and capacity of their factories accordingly while for\nmost consumers, purchase decisions are based on the final price tags, affected\nprimarily by the original prices set by manufacturers.`}),`\n`,(0,e.jsxs)(n.p,{children:[`In contrast, surveillance capitalism relationships with consumers - the users\nof the services - are exploitative rather than constructive. The consumers of\ndigital services have little to no influence on the operations of these\nservices. More and more of our online activities are accompanied by machine\nintelligence beyond our understanding. In fact, they have become behavioral\nmodification tools that are purposely designed to herd consumers like sheep to\nareas of data extraction. For example, Youtube video recommendation algorithms\nare programmed to maximize user on-site time rather than satisfying user needs`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-13\",id:\"user-content-fnref-13\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"13\"})}),`. Another example is the clips sharing platform TikTok\nwith its personalized machine learning contents that keep young users hooked for\nhours`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-14\",id:\"user-content-fnref-14\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"14\"})}),`. Essentially, surveillance capitalists are\ntrying to automate consumers' behaviors, stripping their decision rights.\nConsumers on the other hand, have little to no power over their operations.\ntransformative effects on uncontrolled advancement of surveillance capitalism\nwill be discussed in detail in the next section.`]}),`\n`,(0,e.jsx)(n.p,{children:`This void of power over our own digital experience is what made the behavioral\nvalue reinvestment loop to run smoothly and the manufacture of prediction\nproducts run efficiently. Opposite to information capitalism, the services\nprovided by surveillance capitalists are nothing but hooks that lure users into\nconvenient areas of extraction. We are far from being the end consumer of\nsurveillance capitalism, in reality, we are on the opposite ends: the raw\nmaterials, objects of an inescapable system of continuous extraction.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"instrumentarian-power\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#instrumentarian-power\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Instrumentarian Power\"]}),`\n`,(0,e.jsx)(i,{alt:\"Behavioral automation\",src:\"/images/surveillance-capitalism-overview/automated.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`Competition in any capitalistic economic system drives the innovation of the\nmeans of production. However, in future rendition of surveillance capitalism,\ninnovations may not be required to equal more efficient manufacturing tools and\nextraction. Zuboff suspected that future surveillance capitalists could discover\nthat the best way to maximize their competitive advantages is to automate our\nbehaviors directly. Rather than produce more accurate algorithms and better\ntools of extractions, they may modify user behaviors and align them according to\ntheir customers' needs instead, maximizing the effectiveness of their no longer\nprediction product but behavioral modifications. As portrayed in her words:`}),`\n`,(0,e.jsxs)(n.blockquote,{children:[`\n`,(0,e.jsxs)(n.p,{children:[`\" With this reorientation from knowledge to power, it is no longer enough to\nautomate information flows about us; the goal now is to automate\nus.\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-5\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})})]}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:`This realization among future surveillance capitalists might mark the birth of a\nnew species of power: instrumentarianism. The means of manufacture in\nsurveillance capitalism is now replaced by means of behavioral modification.\nPlayers of the system are now stuck in a continuous loop of intensification of\nthe mean behavioral controls, enjoying the gathering might of instrumentarian\npower that these means endowed.`}),`\n`,(0,e.jsxs)(n.p,{children:[`Moreover, the means of behavioral modification may not be limited to the digital\nworld. Competitive dynamics might nudge the expansion of behavioral futures\nmarkets beyond the digital sphere and into the physical world. The same\nfoundational mechanism used to lure and guide your online activities and\ndecisions such as liking posts, picking a product in an online webstore and\nwatching a particular Youtube video, can be repurposed to physically modifying\nyour behavior in the real world. For example Pokemon Go was Google's first\npublicly known experiment of physical behavioral modification in the real world`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-6\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),`. The viral phenomenon attracts millions of users across\nthe globe and becomes a tremendous financial success for Niantic Lab -\nsurprising to most, is an internal startup at Google - but most importantly for\nGoogle, it is a proof that such expansion of surveillance capitalism into the\nmarket of real-world behavioral modification is possible.`]}),`\n`,(0,e.jsxs)(n.h2,{id:\"conclusion\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#conclusion\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Conclusion\"]}),`\n`,(0,e.jsx)(n.p,{children:`In the essay, I proposed a framework for exploration of surveillance capitalism\nand its relevant discussions. Starting from the fundamental operations of\nextraction and manufacture, we explored the concept of behavioral surplus and\nthe cycle that generates them: the behavioral reinvestment cycle. Then, we\nwitnessed how the inventor and first partitioner of surveillance capitalism:\nGoogle, came up with the solution to the financial problem they faced and the\neventual logical steps that they took to reach the invention of surveillance\ncapitalism. We also explored how different aspects of surveillance capitalists\nare protected and obfuscated and its nature as a man made creation. Finally we\nmoved on to the discussion of the commercial aspect of surveillance capitalism:\nprediction products and its market for exchange and consumption. We end our\nessay with a small discussion of the advancement of surveillance capitalism and\nits elevation from prediction products to behavioral modification as the primary\nmeans of production.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"reference\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#reference\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Reference\"]}),`\n`,(0,e.jsxs)(n.section,{\"data-footnotes\":!0,className:\"footnotes\",children:[(0,e.jsxs)(n.h2,{id:\"footnote-label\",className:\"sr-only\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#footnote-label\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Footnotes\"]}),`\n`,(0,e.jsxs)(n.ol,{children:[`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-1\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Shoshana Zuboff. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. PublicAffairs; 2019.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-1\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-2\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"2\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-3\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"3\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-4\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"4\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-5\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"5\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-6\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"6\"})]})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-2\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Brin S, Page L. The Anatomy of a Large-Scale Hypertextual Web Search Engine. Computer Networks and ISDN Systems [Internet]. 1998 Apr [cited 2022 May 13];30(1):107\\u201317. Available from: https://www.sciencedirect.com/science/article/pii/S016975529800110X\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-2\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-3\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Cukier K. Data, Data Everywhere. ECONOMIST [Internet]. [cited 2022 May 13];394(8671):3\\u20135. Available from: https://search.informit.org/doi/abs/10.3316/agispt.20100985\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-3\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-4\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Coy P. The Secret to Google\\u2019s Success. Business Week. 2006;17.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-4\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-5\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Eric Schmidt, Jared Cohen. The New Digital Age: Transforming Nations, Businesses, and Our Lives. Knopf Doubleday Publishing Group; 2013.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-5\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-6\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Gallagher R. The Surveillance Engine: How the NSA Built Its Own Secret Google. The Intercept. 2014;25.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-6\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-7\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Bishop B. NSA Reveals Its Internet Search Tricks in the Recently Declassified \\u201CUntangling the Web\\u201D [Internet]. The Verge. 2013 [cited 2022 May 13]. Available from: https://www.theverge.com/2013/5/8/4313524/nsa-reveals-its-internet-search-tricks-in-the-recently-declassified-untangling-the-web\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-7\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-8\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Eric Schmidt: Obama\\u2019s Chief Corporate Ally [Internet]. Tech Transparency Project. 2016 [cited 2022 May 13]. Available from: https://www.techtransparencyproject.org/articles/eric-schmidt-obamas-chief-corporate-ally\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-8\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-9\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Google Transparency Report [Internet]. [cited 2022 May 13]. Available from: https://transparencyreport.google.com/?hl=en\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-9\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-9-2\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"2\"})]})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-10\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Nicas BM and J. Paying Professors: Inside Google\\u2019s Academic Influence Campaign. Wall Street Journal [Internet]. 2017 Jul [cited 2022 May 13]; Available from: https://www.wsj.com/articles/paying-professors-inside-googles-academic-influence-campaign-1499785286\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-10\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-11\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Kristol DM. HTTP Cookies: Standards, Privacy, and Politics. ACM Transactions on Internet Technology [Internet]. 2001 Nov [cited 2022 May 13];1(2):151\\u201398. Available from: https://doi.org/10.1145/502152.502153\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-11\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-12\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Smith RM. The Web Bug Faq. Nov. 1999;11:4.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-12\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-13\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Bishop S. Anxiety, Panic and Self-Optimization: Inequalities and the YouTube Algorithm. Convergence [Internet]. 2018 Feb [cited 2022 May 13];24(1):69\\u201384. Available from: https://doi.org/10.1177/1354856517736978\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-13\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-14\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Anderson KE. Getting Acquainted with Social Networks and Apps: It Is Time to Talk about TikTok. Library Hi Tech News [Internet]. 2020 Jan [cited 2022 May 13];37(4):7\\u201312. Available from: https://doi.org/10.1108/LHTN-01-2020-0001\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-14\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`]}),`\n`]})]})}}var k=w;function x(t,a){throw new Error(\"Expected \"+(a?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return v(T);})();\n;return Component;"},"_id":"blog/surveillance-capitalism-overview.mdx","_raw":{"sourceFilePath":"blog/surveillance-capitalism-overview.mdx","sourceFileName":"surveillance-capitalism-overview.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/surveillance-capitalism-overview"},"type":"Blog","readingTime":{"text":"21 min read","minutes":20.365,"time":1221900,"words":4073},"wordCount":4075,"tweetIds":[],"slug":"surveillance-capitalism-overview"}},"__N_SSG":true}
<!DOCTYPE html><html lang="en"><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');if("system"===e||(!e&&true)){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else if(e) d.add(e)}catch(e){}}()</script><title>Surveillance Capitalism: An Overview – Hau Phan</title><meta name="robots" content="follow, index"/><meta content="An overview of Shoshana Zuboff&#x27;s Surveillance Capitalism." name="description"/><meta property="og:url" content="phanthh.github.io/blog/surveillance-capitalism-overview"/><link rel="canonical" href="phanthh.github.io/blog/surveillance-capitalism-overview"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Hau Phan"/><meta property="og:description" content="An overview of Shoshana Zuboff&#x27;s Surveillance Capitalism."/><meta property="og:title" content="Surveillance Capitalism: An Overview – Hau Phan"/><meta property="og:image" content="https://phanthh.github.io/images/surveillance-capitalism-overview/banner.png"/><meta property="article:published_time" content="2021-06-07T00:00:00.000Z"/><meta name="next-head-count" content="14"/><link rel="preload" href="/fonts/ibm-plex-sans-var.woff2" as="font" type="font/woff2" crossorigin="anonymous"/><link href="/static/favicons/favicon.ico" rel="shortcut icon"/><link href="/static/favicons/site.webmanifest" rel="manifest"/><link rel="preconnect" href="https://cdn.usefathom.com" crossorigin=""/><link href="/static/favicons/apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180"/><link href="/static/favicons/favicon-32x32.png" rel="icon" sizes="32x32" type="image/png"/><link href="/static/favicons/favicon-16x16.png" rel="icon" sizes="16x16" type="image/png"/><link color="#4a9885" href="/static/favicons/safari-pinned-tab.svg" rel="mask-icon"/><meta content="#ffffff" name="theme-color"/><meta content="#ffffff" name="msapplication-TileColor"/><meta content="/static/favicons/browserconfig.xml" name="msapplication-config"/><meta content="14d2e73487fa6c71" name="yandex-verification"/><meta content="eZSdmzAXlLkKhNJzfgwDqWORghxnJ8qR9_CHdAh5-xw" name="google-site-verification"/><link rel="preload" href="/_next/static/css/154d03c731028fca.css" as="style"/><link rel="stylesheet" href="/_next/static/css/154d03c731028fca.css" data-n-g=""/><link rel="preload" href="/_next/static/css/c485c78f76af2dd6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/c485c78f76af2dd6.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-3af3f4dceca84f5b.js" defer=""></script><script src="/_next/static/chunks/main-ed45d13e4fde5755.js" defer=""></script><script src="/_next/static/chunks/pages/_app-383b2ec4401a381a.js" defer=""></script><script src="/_next/static/chunks/545-6a7e81f455221330.js" defer=""></script><script src="/_next/static/chunks/601-348e1b5a809230b1.js" defer=""></script><script src="/_next/static/chunks/778-3ceeabf12dc70101.js" defer=""></script><script src="/_next/static/chunks/396-3c75d7c77e18ea12.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5Bslug%5D-2efeaa1cc9ae636e.js" defer=""></script><script src="/_next/static/iFfwlBYB_AelDcwc8h405/_buildManifest.js" defer=""></script><script src="/_next/static/iFfwlBYB_AelDcwc8h405/_ssgManifest.js" defer=""></script><script src="/_next/static/iFfwlBYB_AelDcwc8h405/_middlewareManifest.js" defer=""></script></head><body class="bg-white dark:bg-black text-white dark:text-black"><div id="__next" data-reactroot=""><div class="bg-gray-50 dark:bg-gray-900"><div class="flex flex-col justify-center px-8"></div><nav class="flex items-center justify-between w-full relative max-w-2xl border-gray-200 dark:border-gray-700 mx-auto pt-8 pb-8 sm:pb-16 text-gray-900 bg-gray-50 dark:bg-gray-900 bg-opacity-60 dark:text-gray-100"><a href="#skip" class="skip-nav">Skip to content</a><div class="ml-5 sm:ml-[-0.60rem]"><button class="mobile-menu_burger__wvd0z visible md:hidden" aria-label="Toggle menu" type="button"><svg class="h-5 w-5 absolute text-gray-900 dark:text-gray-100" width="20" height="20" viewBox="0 0 20 20" fill="none" data-hide="false"><path d="M2.5 7.5H17.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M2.5 12.5H17.5" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><svg class="h-5 w-5 absolute text-gray-900 dark:text-gray-100" viewBox="0 0 24 24" width="24" height="24" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" fill="none" shape-rendering="geometricPrecision" data-hide="true"><path d="M18 6L6 18"></path><path d="M6 6l12 12"></path></svg></button><a class="font-normal text-gray-600 dark:text-gray-400 hidden md:inline-block p-1 sm:px-3 sm:py-2 rounded-lg hover:bg-gray-200 dark:hover:bg-gray-800 transition-all" href="/"><span class="capsize">Home</span></a><a class="font-normal text-gray-600 dark:text-gray-400 hidden md:inline-block p-1 sm:px-3 sm:py-2 rounded-lg hover:bg-gray-200 dark:hover:bg-gray-800 transition-all" href="/about"><span class="capsize">About</span></a><a class="font-normal text-gray-600 dark:text-gray-400 hidden md:inline-block p-1 sm:px-3 sm:py-2 rounded-lg hover:bg-gray-200 dark:hover:bg-gray-800 transition-all" href="/blog"><span class="capsize">Blog</span></a><a class="font-normal text-gray-600 dark:text-gray-400 hidden md:inline-block p-1 sm:px-3 sm:py-2 rounded-lg hover:bg-gray-200 dark:hover:bg-gray-800 transition-all" href="/code"><span class="capsize">Code</span></a></div><button aria-label="Toggle Dark Mode" type="button" class="mr-5 sm:mr-0 w-9 h-9 bg-gray-200 rounded-lg dark:bg-gray-600 flex items-center justify-center hover:ring-2 ring-gray-300 transition-all"></button></nav><main id="skip" class="flex flex-col justify-center px-8 bg-gray-50 dark:bg-gray-900"><article class="flex flex-col items-start justify-center w-full max-w-2xl mx-auto mb-16"><h1 class="mb-4 text-3xl font-bold tracking-tight text-black md:text-5xl dark:text-white">Surveillance Capitalism: An Overview</h1><div class="flex flex-col items-start justify-between w-full mt-2 md:flex-row md:items-center"><div class="flex items-center"><p class="ml-2 text-sm text-gray-700 dark:text-gray-300">Hau Phan / <!-- -->June 07, 2021</p></div><p class="mt-2 text-sm text-gray-600 dark:text-gray-400 min-w-32 md:mt-0"> • <!-- -->21 min read</p></div><div class="w-full mt-4 prose dark:prose-dark max-w-none">
<p><em>This was my final essay of CS-E5480: Digital Ethics D. <a href="/static/surveillance-capitalism-overview.pdf">PDF</a></em></p>
<h2 id="introduction"><a class="anchor" href="#introduction"><span class="icon icon-link"></span></a>Introduction</h2>
<p>The 21st century witnessed the rapid digital transformation of the political,
socioeconomic landscape made possible by the internet. Digital technology was
advancing at a pace no one had expected, engendered waves of transformation
across multiple industries. As the burning flame of industrial innovation slowly
died out, the imminent information revolution was on the horizon, waiting to be
set ablaze.</p>
<p>The first decade was remembered as the rise of the first tech companies: Google,
Apple and Microsoft all experienced unprecedented growth during the period.
These accomplishments were celebrated globally, mostly in the US, as new
consumer products and digital services bring many conveniences and life
improvements. Little do we know that during the same period, a group of
individuals had invented an exploitative totalitarian form of capitalism, an
unprecedented event of the digital transformation. Years later did the world
start to realize the nature of these big tech companies and the practices they
employed. Many research papers were published to address antitrust laws and
monopolistic practices of these companies but little addressed the fundamental
economic systems that comprise all their operations. Zuboff was first to realize
and coined the term &quot;surveillance capitalism&quot; to characterize this rogue
economic system. This essay aims to provide an overview of the foundation of
surveillance capitalism, its components, operations, consequences, and a simple
path for exploration of the topic.</p>
<h2 id="outline"><a class="anchor" href="#outline"><span class="icon icon-link"></span></a>Outline</h2>
<p>Surveillance capitalism as a general economical concept was introduced in &quot;A
digital declaration&quot; by Shoshana Zuboff in 2014. The paper marks the first
publication on this mutation of capitalism and sparks many discussions on many
technical practices of Big Tech companies such as Google, Facebook, and
Microsoft. Subsequent scholarly articles further built upon the definition that
had already been laid out in her original paper. In 2019, a major work on
surveillance capitalism was published: &quot;The Age of Surveillance Capitalism: The
Fight for a Human Future at the New Frontier of Power&quot;<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>, in which, she
summarized:</p>
<blockquote>
<p>&quot;Surveillance capitalism is best described as a coup from above, not an
overthrow of the state but rather an overthrow of the people&#x27;s sovereignty and a
prominent force in the perilous drift towards democratic deconsolidation that
now threatens Western liberal democracies.&quot;<sup><a href="#user-content-fn-1" id="user-content-fnref-1-2" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup></p>
</blockquote>
<p>These ominous consequences of surveillance capitalism call for a coherent
ethical framework in an attempt to encapsulate all of its complications. In this
essay, I suggest one such framework, albeit simplified, which consists of three
distinct but interconnected operations that constitute the primary behaviors
observed in surveillance capitalism:</p>
<ul>
<li>The mining of &quot;behavioral surplus&quot; from user activities and experiences.
(extraction)</li>
<li>The feeding of behavioral data into advanced analytical processes
(&quot;machine intelligence&quot;) to produce &quot;prediction products&quot; (manufacture)</li>
<li>The exchange of prediction products on &quot;behavioral futures markets&quot;
(commercialization)</li>
</ul>
<p>Concrete examples will be shown in subsequent sections, where the three primary
operations of surveillance capitalism are laid out and explored in detail.
However, it is necessary that some fundamental theoretical concepts are clearly
understood beforehand.</p>
<h2 id="extraction-and-manufacture"><a class="anchor" href="#extraction-and-manufacture"><span class="icon icon-link"></span></a>Extraction and Manufacture</h2>
<h3 id="machine-intelligence"><a class="anchor" href="#machine-intelligence"><span class="icon icon-link"></span></a>Machine Intelligence</h3>
<p>First, to understand the extraction and manufacturing process of surveillance
capitalism, it is necessary that a frequently used term is clearly understood
beforehand: machine intelligence. The term is used frequently in Zuboff’s &quot;Age
of surveillance capitalism&quot; as a means to bypass the technicality of analytical
practices<sup><a href="#user-content-fn-1" id="user-content-fnref-1-3" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>. In summary, machine intelligence is a
generalization of different specialized computational tools that are used for
data analysis and manufacture of data-based products. It is used frequently as
an umbrella phrase that covers complex computational methods employed by
surveillance capitalists such as artificial intelligence, predictive analytics,
and machine learning, allowing for easy reference in other areas of science. Its
role is to help concentrate our attention on the more important issues of
surveillance capitalism, decentering our focus from the technology it employs to
its objectives instead.</p>
<h3 id="the-behavioral-value-reinvestment-cycle"><a class="anchor" href="#the-behavioral-value-reinvestment-cycle"><span class="icon icon-link"></span></a>The Behavioral Value Reinvestment Cycle</h3>
<!-- -->
<p>A fundamental component of surveillance capitalism is the loop of behavioral
data collection, analysis, services improvements and increased user activities -
the behavioral value reinvestment cycle. It came to existence during the early
invention of surveillance capitalism at Google, when engineers began to apply
machine intelligence to massive collections of user’s past queries. The outputs
of these analyses were then translated to improvements of the user experiences:
better detection of typos, better accuracy and more relevance query
results/suggestions. In other words, the value created was reinvested directly
into improving the user experience, hence the name. These enhancements in turn
attract more users onto the platform, producing even more behavioral data for
analysis. This self-improving mechanism is so effective that only 1 year since
Google&#x27;s establishment, more than seven million user requests were conducted on
its search engine each day. Note that user data was provided at no cost but so
are the enhancements of the platform’s services for users.</p>
<p>Before moving on, there are some misconceptions that need to be pointed out.
Since there is no economic exchange, no price and no profit, it is inaccurate to
think of Google’s users as the customers. There are also no wages involved or
the provision of the means of production: users are not paid for the data they
produced nor do they operate the process of web crawling or its enhancements.
Consequently, it is also wrong to think of them as workers of the cycle.
Finally, there is also a common rhetoric that the user is the &quot;product&quot; of the
system. However, this is also misleading as many aspects of being the &quot;product&quot;
are missing and such expressions further confuse the issue rather than
clarifying it.</p>
<p>The cycle was once all there is to the operations of Google - the first
practitioner of surveillance capitalism. While being different to previous
customer-manufacture relationships by embodying a new mechanism for improving
products and enlarging user base, the behavioral reinvestment cycle is not yet
capitalism, at least in its current stage.</p>
<!-- -->
<p>During the early days of Google, there was the major issue of converting the
service usages to revenues: charging the user for their searches seemed
financially risky and counterproductive; monetizing the searches seemed to be a
dangerous precedent as much of Google&#x27;s indexed information is taken without
payment from the contents’ hosts. The cycle, while possessing the capacity of
producing advanced technologies, is financially unsustainable and failed as a
functional business model. For Google, providing advertisement service was the
only viable solution.</p>
<p>The decision of incorporating advertisements on the company website faced much
opposition at the start, mostly from the company&#x27;s engineers and analysts. Many
engineers of Google&#x27;s AdWords team displayed antipathy toward ads, fearing
uncontrolled bias towards advertisers could steer the company away from user’s
need and degrading searches’ integrity<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>. However,
financial pressure from the fallout of the &quot;dotcom bubble&quot; and intense market
competition in the early 2000s eventually surmounted ethical ideals. To make
more money, it was proposed that advertisements should be automatically targeted
to specific consumers, simplifying the whole process of picking which keywords
inciting which ads for advertisers wanting to use Google online advertising
platform. Finding the solution to this problem eventually led to Google’s
discovery of the centerpiece of surveillance capitalism: the behavioral surplus.</p>
<h3 id="behavioral-surplus"><a class="anchor" href="#behavioral-surplus"><span class="icon icon-link"></span></a>Behavioral Surplus</h3>
<!-- -->
<p>The behavior surplus can be described as by-products formed from user digital
activities, usually existing in the form of behavioral patterns in collection of
user data, readily extracted and transformed into prediction products. It is a
component of the behavioral value reinvestment cycle, the &quot;data exhaust&quot;
produced during user digital activities and their analysis<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup>
. For example, the innocent act of searching the web for a keyword on Google
produces a wake of collateral data such as search counts, phrasing, tonations,
click patterns, dwell times and geographic locations. These excess behavioral
data were once thought to be &quot;exhaust material&quot; and devoid of meaningful values,
thus, were either cached in massive data stores as backups or discarded
entirely. For instance, Google stores user queries results for archiving
purposes in its early days of operation without much knowledge of its hidden
predictive values.</p>
<p>Later analysis of such seemingly unrelated accidental data in massive quantities
or &quot;data mining&quot; reveals behavioral patterns representing sensitive aspects of
human behaviors such as emotions, moods, intentions and needs. Such insights
give Google a powerful competitive advantage over its competitors in the ads
services provider market. For example, a rival search startup Overture had
developed an online auction system to address the scaling problem of online
targeted advertisement. Compelled, Google also developed a similar auction
system but added a transformational functionality: probabilistic modeling of
user’s clicks on ads. The model produced a numeric representation that can be
used to compare the effectiveness of advertiser’s ads on a particular user, not
only maximizing specificity and accuracy but also the number of advertisers
Google&#x27;s can handle at any given time by minimizing. Eventually, Google
succeeded and held the monopoly over web searching, eliminating many companies
in the same service space during the process.<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup></p>
<p>The discovery of behavioral surplus and its capability of behavioral prediction
marked the shift of priorities for Google’s investment strategy. Under the hood,
the behavioral reinvestment cycle was rapidly subordinated by a much more
complex system of operations unbeknown to users. While some of the data relevant
to the improvement of user services will still be reinvested for the benefit of
the consumer, the focus was now placed on the maximization of extracted
behavioral data and development of machine intelligence and operations that
derive values from these data. The purpose of improving services slowly
descended to keeping users engaged and the platform reliable for the intention
of extraction. For Google, it is keeping users reliant on Google for online
browsing and analyzing their queries for better targeted ads. Note that targeted
advertisement is just one of the derivatives of prediction products made
possible by surveillance capitalism and not the only source of values for
surveillance capitalists.</p>
<p>The discovery had also induced another change in corporate mindset at Google:
the company is now compelled to actively hunt for sources of behavioral surplus
and better tools of extraction rather than waiting for accidental patterns
emerging from user activities. This was characterized by Zuboff as the
extraction imperative, in contrast to the production imperative of industrial
capitalism. An example is Google’s &quot;senseless&quot; $1.65 billion acquisition of
Youtube at a time this video-sharing startup was ridden with copyright
infringement lawsuits and a year of profitless operation. Another example is
Facebook’s &quot;reckless&quot; purchase of overvalued unprofitable startups such as the
virtual reality company Oculus ($2 billion) and the messaging platform WhatApps
($19 billion). Only years later was it known that these seemingly ludicrous
business decisions were deliberately aimed at acquiring potential sources of
behavioral surplus that evidently, had brought tremendous amounts of capital for
these first movers of surveillance capitalism.</p>
<h3 id="the-moat"><a class="anchor" href="#the-moat"><span class="icon icon-link"></span></a>The Moat</h3>
<!-- -->
<p>In the discussion of &quot;The moat around the castle&quot;<sup><a href="#user-content-fn-1" id="user-content-fnref-1-4" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup> Zuboff
laid out three main paths of exploration that go into detail how socio-political
circumstances and deliberate practices of surveillance capitalism obfuscate its
employers’ practices and legitimizing their exploitative operations. These
includes: (1) the pursuit and defense of corporate freedom and operational
rights in unregulated space; (2) the sudden federal interests in the
capabilities of behavioral surplus analytics after 9/11; and (3) the
construction of fortifications in politic and academia to protect and deflect
scrutiny of its practices.</p>
<h4 id="right-to-unregulated-space"><a class="anchor" href="#right-to-unregulated-space"><span class="icon icon-link"></span></a>Right to Unregulated Space</h4>
<p>The founders at Google had instituted a corporate structure that allowed the two
opposites to coexist: total controls over the market sphere and the pursuit of
freedom in the public sphere. Such freedom was made possible by the unregulated
nature of cyberspace, mostly due to its novelty as an area of business
activities and economic operations. The cyberspace was characterized by Eric
Schmidt and Jared Cohen in the book &quot;The New Digital Age&quot;, as the world&#x27;s
&quot;largest ungovern space&quot; and truly unbound by &quot;terrestrial laws&quot; and
jurisdictions<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup>. The lack of political institutions is what
made cyberspace attractive to surveillance capitalists: a frictionless space
where behavioral surplus extraction and manufacturing operations are done
smoothly and efficiently without any socio-political hindrances. Such policy
gaps were a direct transformation of the speed gaps between democratic
institutions and bigtech corporations. As admitted by Schmidt in his elaboration
of the 2011 senate testimony, the same antidemocratic measure of leveraging
speed &quot;also work for Google&quot; and described as:</p>
<blockquote>
<p>&quot;This is an Andy Grove (Intel former CEO) formula.... &quot;High tech runs
three-times faster than normal businesses. And the government runs three-times
slower than normal businesses. So we have a nine-times gap.... And so what you
want to do is you want to make sure that the government does not get in the way
and slow things down&quot;</p>
</blockquote>
<h4 id="a-historical-circumstance"><a class="anchor" href="#a-historical-circumstance"><span class="icon icon-link"></span></a>A Historical Circumstance</h4>
<p>The 9/11 terror attacks had caused significant mentality changes among
government officials and the general sentiments toward public surveillance. The
historical circumstance has united the causes of public intelligence agencies
and the early surveillance capitalist Google, producing a unique historical
deformity: surveillance exceptionalism.</p>
<p>The terror attacks had shifted the perception of the federal government on the
practices of online surveillance: from being operations in violation of user
privacy to mission necessities critical to the safety of the public. Both
institutions coveted certainty of user behaviors and were motivated to fulfill
that craving in their respective domains at any cost. The circumstances lent
surveillance capitalism a shelter from scrutiny by slowly legitimizing its
operations in the political sphere. Intelligence agencies were now motivated to
replicate Google’s means of extraction and manufacture, spreading surveillance
capitalism’s ideologies to other sectors of power in society. For example, in
2006, General Keith Alexander outlined his vision for a search tool called
ICREACH that, quoted: &quot;allow unprecedented volumes of metadata to be shared and
analyzed across the many agencies in the Intelligence
Community&quot;<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup>. In 2007 two NSA analysts wrote an
internal training manual on how to find information on the internet<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="true" aria-describedby="footnote-label">7</a></sup>. Such craving slowly translated to reliance, as the
government grew dependent on Silicon Valley to defend security threats looming
in cyberspace, deepening the relationship between governments and surveillance
capitalists.</p>
<h4 id="fortification"><a class="anchor" href="#fortification"><span class="icon icon-link"></span></a>Fortification</h4>
<p>The fortification strategies employed by surveillance capitalists, to my
knowledge, consist of four main demonstrative operations: providing competitive
advantage in electoral politics, personnel migration to and from government
sectors, aggressive lobbying and manipulating public perception by influencing
cultural conversation and academic publications. For example, the 2008 Obama
presidential campaign had Eric Schmidt - the sitting CEO of Google - as one of
the main directors, in charge of implementing state-of-the-art data strategies
that have the potential to shadow traditional political campaigning with the
science of behavioral prediction<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="true" aria-describedby="footnote-label">8</a></sup>. Personnel
migration can be seen frequently through the years of operation at Google: the
Google Transparency Project found that by April 2016, 61 individuals had
migrated from the Google Sphere (company employees plus affiliates and
law/lobbying firms) to the government and over 197 government officials had
moved back<sup><a href="#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref="true" aria-describedby="footnote-label">9</a></sup>. Lobbying is a common practice for Google: in
2014, more than $17 million was spent on lobbying outlay and in 2018, that
number rose to more than $18 million<sup><a href="#user-content-fn-9" id="user-content-fnref-9-2" data-footnote-ref="true" aria-describedby="footnote-label">9</a></sup>. To obfuscate its
practices, Google exercises information manipulation by means of financial
pressure to influence academic research and steering public opinion. Since 2009,
it has been reported that Google had deliberately sought out and funded
university professors for policy papers in agreement with Google&#x27;s positions.<sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref="true" aria-describedby="footnote-label">10</a></sup></p>
<h3 id="a-human-invention"><a class="anchor" href="#a-human-invention"><span class="icon icon-link"></span></a>A Human Invention</h3>
<!-- -->
<p>It is important to emphasize that surveillance capitalism is an intentional
creation, an invention made at a specific time and at a specific place by a
group of individuals. It is not an inevitable result of the digital
transformation, nor an expression of information capitalism. It was deliberately
constructed to solve a business problem at a particular moment in history. If
there was no recession nor the dotcom crash, or the people in charge making the
decision that they had made, the fire might not have started and surveillance
capitalism might have not come to existence.</p>
<p>Many elements of online surveillance predated the creation of surveillance. For
example, &quot;cookies&quot; or small pieces of data stored on the user&#x27;s computer by the
web browser that allow websites to remember user information and activities, had
already been introduced in 1994 by Netscape<sup><a href="#user-content-fn-11" id="user-content-fnref-11" data-footnote-ref="true" aria-describedby="footnote-label">11</a></sup>. Other
similar online browsing trackers and surveillance tools such as &quot;web beacon&quot; or
&quot;web bugs&quot; were well-known among experts during the late 1990s<sup><a href="#user-content-fn-12" id="user-content-fnref-12" data-footnote-ref="true" aria-describedby="footnote-label">12</a></sup>. However, it was Google that integrated a wide range of
online surveillance mechanisms, from cookies to predictive analytics that allow
for the institution of a new logic of accumulation by means of data extraction
and analysis, establishing a new market for commercialized prediction products
where customers are businesses, not consumers.</p>
<h2 id="commercialization"><a class="anchor" href="#commercialization"><span class="icon icon-link"></span></a>Commercialization</h2>
<h3 id="prediction-product"><a class="anchor" href="#prediction-product"><span class="icon icon-link"></span></a>Prediction Product</h3>
<!-- -->
<p>Surveillance capitalism is a derivative of capitalism and thus the exchange of
products among its actors is one of its fundamental activities. Differ from
popular industrial capitalism where commodities are manufactured goods traded on
the open market, surveillance capitalism goods are prediction products that
forecast future behaviors of users. These include, but not limited to: thoughts,
actions, emotions, moods, desires, physical needs, psychological needs,
short-term intentions and possibly long-term intentions, given sufficiently
powerful behavioral data. It is the nature of prediction products that explains
why Google constantly distant themselves from the notion of selling personal
data. Google does not sell the raw materials, they sell the predictions. The
claim of privacy purity is just a superficial excuse that conceal the backstage
operations of surveillance capitalism it employs.</p>
<p>Prediction products reduce uncertainty in their customers&#x27; operations, advising
them where and when to allocate resources. The quality of prediction products is
a direct translation of its accuracy: how good are their approximations of
reality. The more precise the prediction, the lower the risk and the higher the
revenue. For the fledgling company Google, targeted advertisements are the
embodiment of prediction products. However, as demonstrated by Zuboff,
advertising is far from being the end of the commodification of behavioral data.</p>
<h3 id="behavioral-market"><a class="anchor" href="#behavioral-market"><span class="icon icon-link"></span></a>Behavioral Market</h3>
<!-- -->
<p>Prediction products after being fabricated by machine intelligence from massive
collections of behavioral surplus are then sold on a new kind of market: the
behavioral futures market. The market exchanges exclusively the knowledge of
future behaviors of consumers. Although for most of the history of surveillance
capitalism, the dominant players of this new marketplace are advertisers, there
is no reason why such markets are limited to this particular group.</p>
<p>The scope of behavioral futures markets has expanded throughout the advance of
surveillance capitalism in modern society, both in terms of potential customers
and the variety of traded products: once confined to the online targeted
advertisement services, products of surveillance capitalists now may comprise
offline predictions of users locations, emotions and actions, automated tools
that generated those predictions, and ultimately, behavioral modification tools
that align user behavior to the business’s means of profit-making. While
surveillance capitalism is based on classical capitalism and shares many common
dynamics in its commercialization, there are necessary distinctions between the
two that are worth highlighting.</p>
<p>The classical producer-consumer relationship of capitalism is starkly different
from this freshly formed variance of it. On one hand, classical capitalism
allows for constructive relations between the manufacturers and the consumers,
in which the former creates supply and the latter induces demand. Manufacturers
base their course of actions on the state of the consumer market, adjusting
product price, quality and capacity of their factories accordingly while for
most consumers, purchase decisions are based on the final price tags, affected
primarily by the original prices set by manufacturers.</p>
<p>In contrast, surveillance capitalism relationships with consumers - the users
of the services - are exploitative rather than constructive. The consumers of
digital services have little to no influence on the operations of these
services. More and more of our online activities are accompanied by machine
intelligence beyond our understanding. In fact, they have become behavioral
modification tools that are purposely designed to herd consumers like sheep to
areas of data extraction. For example, Youtube video recommendation algorithms
are programmed to maximize user on-site time rather than satisfying user needs<sup><a href="#user-content-fn-13" id="user-content-fnref-13" data-footnote-ref="true" aria-describedby="footnote-label">13</a></sup>. Another example is the clips sharing platform TikTok
with its personalized machine learning contents that keep young users hooked for
hours<sup><a href="#user-content-fn-14" id="user-content-fnref-14" data-footnote-ref="true" aria-describedby="footnote-label">14</a></sup>. Essentially, surveillance capitalists are
trying to automate consumers&#x27; behaviors, stripping their decision rights.
Consumers on the other hand, have little to no power over their operations.
transformative effects on uncontrolled advancement of surveillance capitalism
will be discussed in detail in the next section.</p>
<p>This void of power over our own digital experience is what made the behavioral
value reinvestment loop to run smoothly and the manufacture of prediction
products run efficiently. Opposite to information capitalism, the services
provided by surveillance capitalists are nothing but hooks that lure users into
convenient areas of extraction. We are far from being the end consumer of
surveillance capitalism, in reality, we are on the opposite ends: the raw
materials, objects of an inescapable system of continuous extraction.</p>
<h2 id="instrumentarian-power"><a class="anchor" href="#instrumentarian-power"><span class="icon icon-link"></span></a>Instrumentarian Power</h2>
<!-- -->
<p>Competition in any capitalistic economic system drives the innovation of the
means of production. However, in future rendition of surveillance capitalism,
innovations may not be required to equal more efficient manufacturing tools and
extraction. Zuboff suspected that future surveillance capitalists could discover
that the best way to maximize their competitive advantages is to automate our
behaviors directly. Rather than produce more accurate algorithms and better
tools of extractions, they may modify user behaviors and align them according to
their customers&#x27; needs instead, maximizing the effectiveness of their no longer
prediction product but behavioral modifications. As portrayed in her words:</p>
<blockquote>
<p>&quot; With this reorientation from knowledge to power, it is no longer enough to
automate information flows about us; the goal now is to automate
us.&quot;<sup><a href="#user-content-fn-1" id="user-content-fnref-1-5" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup></p>
</blockquote>
<p>This realization among future surveillance capitalists might mark the birth of a
new species of power: instrumentarianism. The means of manufacture in
surveillance capitalism is now replaced by means of behavioral modification.
Players of the system are now stuck in a continuous loop of intensification of
the mean behavioral controls, enjoying the gathering might of instrumentarian
power that these means endowed.</p>
<p>Moreover, the means of behavioral modification may not be limited to the digital
world. Competitive dynamics might nudge the expansion of behavioral futures
markets beyond the digital sphere and into the physical world. The same
foundational mechanism used to lure and guide your online activities and
decisions such as liking posts, picking a product in an online webstore and
watching a particular Youtube video, can be repurposed to physically modifying
your behavior in the real world. For example Pokemon Go was Google&#x27;s first
publicly known experiment of physical behavioral modification in the real world<sup><a href="#user-content-fn-1" id="user-content-fnref-1-6" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>. The viral phenomenon attracts millions of users across
the globe and becomes a tremendous financial success for Niantic Lab -
surprising to most, is an internal startup at Google - but most importantly for
Google, it is a proof that such expansion of surveillance capitalism into the
market of real-world behavioral modification is possible.</p>
<h2 id="conclusion"><a class="anchor" href="#conclusion"><span class="icon icon-link"></span></a>Conclusion</h2>
<p>In the essay, I proposed a framework for exploration of surveillance capitalism
and its relevant discussions. Starting from the fundamental operations of
extraction and manufacture, we explored the concept of behavioral surplus and
the cycle that generates them: the behavioral reinvestment cycle. Then, we
witnessed how the inventor and first partitioner of surveillance capitalism:
Google, came up with the solution to the financial problem they faced and the
eventual logical steps that they took to reach the invention of surveillance
capitalism. We also explored how different aspects of surveillance capitalists
are protected and obfuscated and its nature as a man made creation. Finally we
moved on to the discussion of the commercial aspect of surveillance capitalism:
prediction products and its market for exchange and consumption. We end our
essay with a small discussion of the advancement of surveillance capitalism and
its elevation from prediction products to behavioral modification as the primary
means of production.</p>
<h2 id="reference"><a class="anchor" href="#reference"><span class="icon icon-link"></span></a>Reference</h2>
<section data-footnotes="true" class="footnotes"><h2 id="footnote-label" class="sr-only"><a class="anchor" href="#footnote-label"><span class="icon icon-link"></span></a>Footnotes</h2>
<ol>
<li id="user-content-fn-1">
<p>1. Shoshana Zuboff. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. PublicAffairs; 2019.
 <a href="#user-content-fnref-1" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a> <a href="#user-content-fnref-1-2" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<sup>2</sup></a> <a href="#user-content-fnref-1-3" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<sup>3</sup></a> <a href="#user-content-fnref-1-4" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<sup>4</sup></a> <a href="#user-content-fnref-1-5" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<sup>5</sup></a> <a href="#user-content-fnref-1-6" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<sup>6</sup></a></p>
</li>
<li id="user-content-fn-2">
<p>1. Brin S, Page L. The Anatomy of a Large-Scale Hypertextual Web Search Engine. Computer Networks and ISDN Systems [Internet]. 1998 Apr [cited 2022 May 13];30(1):107–17. Available from: https://www.sciencedirect.com/science/article/pii/S016975529800110X
 <a href="#user-content-fnref-2" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>1. Cukier K. Data, Data Everywhere. ECONOMIST [Internet]. [cited 2022 May 13];394(8671):3–5. Available from: https://search.informit.org/doi/abs/10.3316/agispt.20100985
 <a href="#user-content-fnref-3" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>1. Coy P. The Secret to Google’s Success. Business Week. 2006;17.
 <a href="#user-content-fnref-4" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>1. Eric Schmidt, Jared Cohen. The New Digital Age: Transforming Nations, Businesses, and Our Lives. Knopf Doubleday Publishing Group; 2013.
 <a href="#user-content-fnref-5" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-6">
<p>1. Gallagher R. The Surveillance Engine: How the NSA Built Its Own Secret Google. The Intercept. 2014;25.
 <a href="#user-content-fnref-6" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-7">
<p>1. Bishop B. NSA Reveals Its Internet Search Tricks in the Recently Declassified “Untangling the Web” [Internet]. The Verge. 2013 [cited 2022 May 13]. Available from: https://www.theverge.com/2013/5/8/4313524/nsa-reveals-its-internet-search-tricks-in-the-recently-declassified-untangling-the-web
 <a href="#user-content-fnref-7" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-8">
<p>1. Eric Schmidt: Obama’s Chief Corporate Ally [Internet]. Tech Transparency Project. 2016 [cited 2022 May 13]. Available from: https://www.techtransparencyproject.org/articles/eric-schmidt-obamas-chief-corporate-ally
 <a href="#user-content-fnref-8" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-9">
<p>1. Google Transparency Report [Internet]. [cited 2022 May 13]. Available from: https://transparencyreport.google.com/?hl=en
 <a href="#user-content-fnref-9" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a> <a href="#user-content-fnref-9-2" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-10">
<p>1. Nicas BM and J. Paying Professors: Inside Google’s Academic Influence Campaign. Wall Street Journal [Internet]. 2017 Jul [cited 2022 May 13]; Available from: https://www.wsj.com/articles/paying-professors-inside-googles-academic-influence-campaign-1499785286
 <a href="#user-content-fnref-10" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-11">
<p>1. Kristol DM. HTTP Cookies: Standards, Privacy, and Politics. ACM Transactions on Internet Technology [Internet]. 2001 Nov [cited 2022 May 13];1(2):151–98. Available from: https://doi.org/10.1145/502152.502153
 <a href="#user-content-fnref-11" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-12">
<p>1. Smith RM. The Web Bug Faq. Nov. 1999;11:4.
 <a href="#user-content-fnref-12" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-13">
<p>1. Bishop S. Anxiety, Panic and Self-Optimization: Inequalities and the YouTube Algorithm. Convergence [Internet]. 2018 Feb [cited 2022 May 13];24(1):69–84. Available from: https://doi.org/10.1177/1354856517736978
 <a href="#user-content-fnref-13" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
<li id="user-content-fn-14">
<p>1. Anderson KE. Getting Acquainted with Social Networks and Apps: It Is Time to Talk about TikTok. Library Hi Tech News [Internet]. 2020 Jan [cited 2022 May 13];37(4):7–12. Available from: https://doi.org/10.1108/LHTN-01-2020-0001
 <a href="#user-content-fnref-14" data-footnote-backref="true" class="data-footnote-backref" aria-label="Back to content">↩</a></p>
</li>
</ol>
</section></div><div class="text-sm text-gray-700 dark:text-gray-300"><a href="https://github.com/phanthh/phanthh.github.io/edit/main/data/blog/surveillance-capitalism-overview.mdx" target="_blank" rel="noopener noreferrer">Edit on GitHub</a> • </div></article><div class="border border-blue-200 rounded p-6 my-4 w-full dark:border-gray-800 bg-blue-50 dark:bg-blue-opaque max-w-2xl mx-auto mb-16"><p class="text-lg md:text-xl font-bold text-gray-900 dark:text-gray-100">Contact me!</p><p class="my-1 text-gray-800 dark:text-gray-200">Below are my primary work email address. <br/>You can also message me on<!-- --> <a class="text-gray-500 hover:text-gray-600 transition text-center sm:text-left" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/phanthh/">LinkedIn</a> <!-- -->and<!-- --> <a class="text-gray-500 hover:text-gray-600 transition text-center sm:text-left" target="_blank" rel="noopener noreferrer" href="https://www.facebook.com/phanthh1/">Facebook</a>.</p><div class="relative my-4"><input type="email" aria-label="Email for newsletter" placeholder="hau.phan@aalto.fi" autoComplete="email" required="" disabled="" class="px-4 py-2 mt-1 focus:ring-blue-500 focus:border-blue-500 block w-full border-gray-300 rounded-md bg-white dark:bg-gray-800 text-gray-900 dark:text-gray-100 pr-32"/><button class="transition-all flex items-center justify-center absolute right-1 top-1 px-4 pt-1 font-medium h-8 bg-gray-100 dark:bg-gray-700 text-gray-900 dark:text-gray-100 rounded w-24">Copy</button><div class="text-gray-700 mt-2 dark:text-gray-500 text-sm ">Reply times tend to be 1-2 days (at most).</div></div></div><footer class="flex flex-col justify-center items-start max-w-2xl mx-auto w-full mb-8"><hr class="w-full border-1 border-gray-200 dark:border-gray-800 mb-8"/><div class="w-full max-w-2xl grid grid-cols-1 gap-4 pb-16 grid-cols-2 sm:grid-cols-3"><div class="flex flex-col space-y-4"><a class="text-gray-500 hover:text-gray-600 transition" href="/">Home</a><a class="text-gray-500 hover:text-gray-600 transition" href="/about">About</a><a class="text-gray-500 hover:text-gray-600 transition" href="/blogs">Blog</a></div><div class="flex flex-col space-y-4"><a class="text-gray-500 hover:text-gray-600 transition" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/phanthh/">LinkedIn</a><a class="text-gray-500 hover:text-gray-600 transition" target="_blank" rel="noopener noreferrer" href="https://github.com/phanthh">GitHub</a><a class="text-gray-500 hover:text-gray-600 transition" target="_blank" rel="noopener noreferrer" href="https://www.facebook.com/phanthh1/">Facebook</a></div><div class="flex flex-col space-y-4"><a class="text-gray-500 hover:text-gray-600 transition" href="/uses">Uses</a><a class="text-gray-500 hover:text-gray-600 transition" href="/tba">TBA</a><a class="text-gray-500 hover:text-gray-600 transition" href="/tba">TBA</a></div></div><div class="flex justify-center w-full"><p class="text-gray-500">Inspired by<!-- --> <a class="text-gray-500 hover:text-gray-600 transition underline" href="https://leerob.io/">leerob.io</a></p></div></footer></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"Surveillance Capitalism: An Overview","publishedAt":"2021-06-07","summary":"An overview of Shoshana Zuboff's Surveillance Capitalism.","image":"/images/surveillance-capitalism-overview/banner.png","body":{"raw":"\n\u003cImage\n  alt={`Surveillance Capitalism: An Overview`}\n  src={`/images/surveillance-capitalism-overview/banner.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\n_This was my final essay of CS-E5480: Digital Ethics D. [PDF](/static/surveillance-capitalism-overview.pdf)_\n\n## Introduction\n\nThe 21st century witnessed the rapid digital transformation of the political,\nsocioeconomic landscape made possible by the internet. Digital technology was\nadvancing at a pace no one had expected, engendered waves of transformation\nacross multiple industries. As the burning flame of industrial innovation slowly\ndied out, the imminent information revolution was on the horizon, waiting to be\nset ablaze.\n\nThe first decade was remembered as the rise of the first tech companies: Google,\nApple and Microsoft all experienced unprecedented growth during the period.\nThese accomplishments were celebrated globally, mostly in the US, as new\nconsumer products and digital services bring many conveniences and life\nimprovements. Little do we know that during the same period, a group of\nindividuals had invented an exploitative totalitarian form of capitalism, an\nunprecedented event of the digital transformation. Years later did the world\nstart to realize the nature of these big tech companies and the practices they\nemployed. Many research papers were published to address antitrust laws and\nmonopolistic practices of these companies but little addressed the fundamental\neconomic systems that comprise all their operations. Zuboff was first to realize\nand coined the term \"surveillance capitalism\" to characterize this rogue\neconomic system. This essay aims to provide an overview of the foundation of\nsurveillance capitalism, its components, operations, consequences, and a simple\npath for exploration of the topic.\n\n## Outline\n\nSurveillance capitalism as a general economical concept was introduced in \"A\ndigital declaration\" by Shoshana Zuboff in 2014. The paper marks the first\npublication on this mutation of capitalism and sparks many discussions on many\ntechnical practices of Big Tech companies such as Google, Facebook, and\nMicrosoft. Subsequent scholarly articles further built upon the definition that\nhad already been laid out in her original paper. In 2019, a major work on\nsurveillance capitalism was published: \"The Age of Surveillance Capitalism: The\nFight for a Human Future at the New Frontier of Power\" (@shoshanazuboffAgeSurveillanceCapitalism2019), in which, she\nsummarized:\n\n\u003e \"Surveillance capitalism is best described as a coup from above, not an\n\u003e overthrow of the state but rather an overthrow of the people's sovereignty and a\n\u003e prominent force in the perilous drift towards democratic deconsolidation that\n\u003e now threatens Western liberal democracies.\"(@shoshanazuboffAgeSurveillanceCapitalism2019)\n\nThese ominous consequences of surveillance capitalism call for a coherent\nethical framework in an attempt to encapsulate all of its complications. In this\nessay, I suggest one such framework, albeit simplified, which consists of three\ndistinct but interconnected operations that constitute the primary behaviors\nobserved in surveillance capitalism:\n\n- The mining of \"behavioral surplus\" from user activities and experiences.\n  (extraction)\n- The feeding of behavioral data into advanced analytical processes\n  (\"machine intelligence\") to produce \"prediction products\" (manufacture)\n- The exchange of prediction products on \"behavioral futures markets\"\n  (commercialization)\n\nConcrete examples will be shown in subsequent sections, where the three primary\noperations of surveillance capitalism are laid out and explored in detail.\nHowever, it is necessary that some fundamental theoretical concepts are clearly\nunderstood beforehand.\n\n## Extraction and Manufacture\n\n### Machine Intelligence\n\nFirst, to understand the extraction and manufacturing process of surveillance\ncapitalism, it is necessary that a frequently used term is clearly understood\nbeforehand: machine intelligence. The term is used frequently in Zuboff’s \"Age\nof surveillance capitalism\" as a means to bypass the technicality of analytical\npractices (@shoshanazuboffAgeSurveillanceCapitalism2019). In summary, machine intelligence is a\ngeneralization of different specialized computational tools that are used for\ndata analysis and manufacture of data-based products. It is used frequently as\nan umbrella phrase that covers complex computational methods employed by\nsurveillance capitalists such as artificial intelligence, predictive analytics,\nand machine learning, allowing for easy reference in other areas of science. Its\nrole is to help concentrate our attention on the more important issues of\nsurveillance capitalism, decentering our focus from the technology it employs to\nits objectives instead.\n\n### The Behavioral Value Reinvestment Cycle\n\n\u003cImage\n  alt={`The Behavioral Value Reinvestment Cycle`}\n  src={`/images/surveillance-capitalism-overview/cycle.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nA fundamental component of surveillance capitalism is the loop of behavioral\ndata collection, analysis, services improvements and increased user activities -\nthe behavioral value reinvestment cycle. It came to existence during the early\ninvention of surveillance capitalism at Google, when engineers began to apply\nmachine intelligence to massive collections of user’s past queries. The outputs\nof these analyses were then translated to improvements of the user experiences:\nbetter detection of typos, better accuracy and more relevance query\nresults/suggestions. In other words, the value created was reinvested directly\ninto improving the user experience, hence the name. These enhancements in turn\nattract more users onto the platform, producing even more behavioral data for\nanalysis. This self-improving mechanism is so effective that only 1 year since\nGoogle's establishment, more than seven million user requests were conducted on\nits search engine each day. Note that user data was provided at no cost but so\nare the enhancements of the platform’s services for users.\n\nBefore moving on, there are some misconceptions that need to be pointed out.\nSince there is no economic exchange, no price and no profit, it is inaccurate to\nthink of Google’s users as the customers. There are also no wages involved or\nthe provision of the means of production: users are not paid for the data they\nproduced nor do they operate the process of web crawling or its enhancements.\nConsequently, it is also wrong to think of them as workers of the cycle.\nFinally, there is also a common rhetoric that the user is the \"product\" of the\nsystem. However, this is also misleading as many aspects of being the \"product\"\nare missing and such expressions further confuse the issue rather than\nclarifying it.\n\nThe cycle was once all there is to the operations of Google - the first\npractitioner of surveillance capitalism. While being different to previous\ncustomer-manufacture relationships by embodying a new mechanism for improving\nproducts and enlarging user base, the behavioral reinvestment cycle is not yet\ncapitalism, at least in its current stage.\n\n\u003cImage\n  alt={`Google HQ`}\n  src={`/images/surveillance-capitalism-overview/google-hq.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nDuring the early days of Google, there was the major issue of converting the\nservice usages to revenues: charging the user for their searches seemed\nfinancially risky and counterproductive; monetizing the searches seemed to be a\ndangerous precedent as much of Google's indexed information is taken without\npayment from the contents’ hosts. The cycle, while possessing the capacity of\nproducing advanced technologies, is financially unsustainable and failed as a\nfunctional business model. For Google, providing advertisement service was the\nonly viable solution.\n\nThe decision of incorporating advertisements on the company website faced much\nopposition at the start, mostly from the company's engineers and analysts. Many\nengineers of Google's AdWords team displayed antipathy toward ads, fearing\nuncontrolled bias towards advertisers could steer the company away from user’s\nneed and degrading searches’ integrity (@brinAnatomyLargescaleHypertextual1998). However,\nfinancial pressure from the fallout of the \"dotcom bubble\" and intense market\ncompetition in the early 2000s eventually surmounted ethical ideals. To make\nmore money, it was proposed that advertisements should be automatically targeted\nto specific consumers, simplifying the whole process of picking which keywords\ninciting which ads for advertisers wanting to use Google online advertising\nplatform. Finding the solution to this problem eventually led to Google’s\ndiscovery of the centerpiece of surveillance capitalism: the behavioral surplus.\n\n### Behavioral Surplus\n\n\u003cImage\n  alt={`The discovery of behavioral surplus`}\n  src={`/images/surveillance-capitalism-overview/surplus.png`}\n  width={1280}\n  height={1000}\n  priority\n/\u003e\n\nThe behavior surplus can be described as by-products formed from user digital\nactivities, usually existing in the form of behavioral patterns in collection of\nuser data, readily extracted and transformed into prediction products. It is a\ncomponent of the behavioral value reinvestment cycle, the \"data exhaust\"\nproduced during user digital activities and their analysis (@cukierDataDataEverywhere)\n. For example, the innocent act of searching the web for a keyword on Google\nproduces a wake of collateral data such as search counts, phrasing, tonations,\nclick patterns, dwell times and geographic locations. These excess behavioral\ndata were once thought to be \"exhaust material\" and devoid of meaningful values,\nthus, were either cached in massive data stores as backups or discarded\nentirely. For instance, Google stores user queries results for archiving\npurposes in its early days of operation without much knowledge of its hidden\npredictive values.\n\nLater analysis of such seemingly unrelated accidental data in massive quantities\nor \"data mining\" reveals behavioral patterns representing sensitive aspects of\nhuman behaviors such as emotions, moods, intentions and needs. Such insights\ngive Google a powerful competitive advantage over its competitors in the ads\nservices provider market. For example, a rival search startup Overture had\ndeveloped an online auction system to address the scaling problem of online\ntargeted advertisement. Compelled, Google also developed a similar auction\nsystem but added a transformational functionality: probabilistic modeling of\nuser’s clicks on ads. The model produced a numeric representation that can be\nused to compare the effectiveness of advertiser’s ads on a particular user, not\nonly maximizing specificity and accuracy but also the number of advertisers\nGoogle's can handle at any given time by minimizing. Eventually, Google\nsucceeded and held the monopoly over web searching, eliminating many companies\nin the same service space during the process. (@coySecretGoogleSuccess2006)\n\nThe discovery of behavioral surplus and its capability of behavioral prediction\nmarked the shift of priorities for Google’s investment strategy. Under the hood,\nthe behavioral reinvestment cycle was rapidly subordinated by a much more\ncomplex system of operations unbeknown to users. While some of the data relevant\nto the improvement of user services will still be reinvested for the benefit of\nthe consumer, the focus was now placed on the maximization of extracted\nbehavioral data and development of machine intelligence and operations that\nderive values from these data. The purpose of improving services slowly\ndescended to keeping users engaged and the platform reliable for the intention\nof extraction. For Google, it is keeping users reliant on Google for online\nbrowsing and analyzing their queries for better targeted ads. Note that targeted\nadvertisement is just one of the derivatives of prediction products made\npossible by surveillance capitalism and not the only source of values for\nsurveillance capitalists.\n\nThe discovery had also induced another change in corporate mindset at Google:\nthe company is now compelled to actively hunt for sources of behavioral surplus\nand better tools of extraction rather than waiting for accidental patterns\nemerging from user activities. This was characterized by Zuboff as the\nextraction imperative, in contrast to the production imperative of industrial\ncapitalism. An example is Google’s \"senseless\" \\$1.65 billion acquisition of\nYoutube at a time this video-sharing startup was ridden with copyright\ninfringement lawsuits and a year of profitless operation. Another example is\nFacebook’s \"reckless\" purchase of overvalued unprofitable startups such as the\nvirtual reality company Oculus (\\$2 billion) and the messaging platform WhatApps\n(\\$19 billion). Only years later was it known that these seemingly ludicrous\nbusiness decisions were deliberately aimed at acquiring potential sources of\nbehavioral surplus that evidently, had brought tremendous amounts of capital for\nthese first movers of surveillance capitalism.\n\n### The Moat\n\n\u003cImage\n  alt={`The discovery of behavioral surplus`}\n  src={`/images/surveillance-capitalism-overview/moat.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nIn the discussion of \"The moat around the castle\" (@shoshanazuboffAgeSurveillanceCapitalism2019) Zuboff\nlaid out three main paths of exploration that go into detail how socio-political\ncircumstances and deliberate practices of surveillance capitalism obfuscate its\nemployers’ practices and legitimizing their exploitative operations. These\nincludes: (1) the pursuit and defense of corporate freedom and operational\nrights in unregulated space; (2) the sudden federal interests in the\ncapabilities of behavioral surplus analytics after 9/11; and (3) the\nconstruction of fortifications in politic and academia to protect and deflect\nscrutiny of its practices.\n\n#### Right to Unregulated Space\n\nThe founders at Google had instituted a corporate structure that allowed the two\nopposites to coexist: total controls over the market sphere and the pursuit of\nfreedom in the public sphere. Such freedom was made possible by the unregulated\nnature of cyberspace, mostly due to its novelty as an area of business\nactivities and economic operations. The cyberspace was characterized by Eric\nSchmidt and Jared Cohen in the book \"The New Digital Age\", as the world's\n\"largest ungovern space\" and truly unbound by \"terrestrial laws\" and\njurisdictions (@ericschmidtNewDigitalAge2013). The lack of political institutions is what\nmade cyberspace attractive to surveillance capitalists: a frictionless space\nwhere behavioral surplus extraction and manufacturing operations are done\nsmoothly and efficiently without any socio-political hindrances. Such policy\ngaps were a direct transformation of the speed gaps between democratic\ninstitutions and bigtech corporations. As admitted by Schmidt in his elaboration\nof the 2011 senate testimony, the same antidemocratic measure of leveraging\nspeed \"also work for Google\" and described as:\n\n\u003e \"This is an Andy Grove (Intel former CEO) formula.... \"High tech runs\n\u003e three-times faster than normal businesses. And the government runs three-times\n\u003e slower than normal businesses. So we have a nine-times gap.... And so what you\n\u003e want to do is you want to make sure that the government does not get in the way\n\u003e and slow things down\"\n\n#### A Historical Circumstance\n\nThe 9/11 terror attacks had caused significant mentality changes among\ngovernment officials and the general sentiments toward public surveillance. The\nhistorical circumstance has united the causes of public intelligence agencies\nand the early surveillance capitalist Google, producing a unique historical\ndeformity: surveillance exceptionalism.\n\nThe terror attacks had shifted the perception of the federal government on the\npractices of online surveillance: from being operations in violation of user\nprivacy to mission necessities critical to the safety of the public. Both\ninstitutions coveted certainty of user behaviors and were motivated to fulfill\nthat craving in their respective domains at any cost. The circumstances lent\nsurveillance capitalism a shelter from scrutiny by slowly legitimizing its\noperations in the political sphere. Intelligence agencies were now motivated to\nreplicate Google’s means of extraction and manufacture, spreading surveillance\ncapitalism’s ideologies to other sectors of power in society. For example, in\n2006, General Keith Alexander outlined his vision for a search tool called\nICREACH that, quoted: \"allow unprecedented volumes of metadata to be shared and\nanalyzed across the many agencies in the Intelligence\nCommunity\"(@gallagherSurveillanceEngineHow2014). In 2007 two NSA analysts wrote an\ninternal training manual on how to find information on the internet\n(@bishopNSARevealsIts2013). Such craving slowly translated to reliance, as the\ngovernment grew dependent on Silicon Valley to defend security threats looming\nin cyberspace, deepening the relationship between governments and surveillance\ncapitalists.\n\n#### Fortification\n\nThe fortification strategies employed by surveillance capitalists, to my\nknowledge, consist of four main demonstrative operations: providing competitive\nadvantage in electoral politics, personnel migration to and from government\nsectors, aggressive lobbying and manipulating public perception by influencing\ncultural conversation and academic publications. For example, the 2008 Obama\npresidential campaign had Eric Schmidt - the sitting CEO of Google - as one of\nthe main directors, in charge of implementing state-of-the-art data strategies\nthat have the potential to shadow traditional political campaigning with the\nscience of behavioral prediction (@EricSchmidtObama2016). Personnel\nmigration can be seen frequently through the years of operation at Google: the\nGoogle Transparency Project found that by April 2016, 61 individuals had\nmigrated from the Google Sphere (company employees plus affiliates and\nlaw/lobbying firms) to the government and over 197 government officials had\nmoved back (@GoogleTransparencyReport). Lobbying is a common practice for Google: in\n2014, more than \\$17 million was spent on lobbying outlay and in 2018, that\nnumber rose to more than \\$18 million (@GoogleTransparencyReport). To obfuscate its\npractices, Google exercises information manipulation by means of financial\npressure to influence academic research and steering public opinion. Since 2009,\nit has been reported that Google had deliberately sought out and funded\nuniversity professors for policy papers in agreement with Google's positions.\n(@nicasPayingProfessorsGoogle2017)\n\n### A Human Invention\n\n\u003cImage\n  alt={`Human invention`}\n  src={`/images/surveillance-capitalism-overview/invention.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nIt is important to emphasize that surveillance capitalism is an intentional\ncreation, an invention made at a specific time and at a specific place by a\ngroup of individuals. It is not an inevitable result of the digital\ntransformation, nor an expression of information capitalism. It was deliberately\nconstructed to solve a business problem at a particular moment in history. If\nthere was no recession nor the dotcom crash, or the people in charge making the\ndecision that they had made, the fire might not have started and surveillance\ncapitalism might have not come to existence.\n\nMany elements of online surveillance predated the creation of surveillance. For\nexample, \"cookies\" or small pieces of data stored on the user's computer by the\nweb browser that allow websites to remember user information and activities, had\nalready been introduced in 1994 by Netscape (@kristolHTTPCookiesStandards2001). Other\nsimilar online browsing trackers and surveillance tools such as \"web beacon\" or\n\"web bugs\" were well-known among experts during the late 1990s\n(@smithWebBugFaq1999). However, it was Google that integrated a wide range of\nonline surveillance mechanisms, from cookies to predictive analytics that allow\nfor the institution of a new logic of accumulation by means of data extraction\nand analysis, establishing a new market for commercialized prediction products\nwhere customers are businesses, not consumers.\n\n## Commercialization\n\n### Prediction Product\n\n\u003cImage\n  alt={`Prediction product`}\n  src={`/images/surveillance-capitalism-overview/product.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nSurveillance capitalism is a derivative of capitalism and thus the exchange of\nproducts among its actors is one of its fundamental activities. Differ from\npopular industrial capitalism where commodities are manufactured goods traded on\nthe open market, surveillance capitalism goods are prediction products that\nforecast future behaviors of users. These include, but not limited to: thoughts,\nactions, emotions, moods, desires, physical needs, psychological needs,\nshort-term intentions and possibly long-term intentions, given sufficiently\npowerful behavioral data. It is the nature of prediction products that explains\nwhy Google constantly distant themselves from the notion of selling personal\ndata. Google does not sell the raw materials, they sell the predictions. The\nclaim of privacy purity is just a superficial excuse that conceal the backstage\noperations of surveillance capitalism it employs.\n\nPrediction products reduce uncertainty in their customers' operations, advising\nthem where and when to allocate resources. The quality of prediction products is\na direct translation of its accuracy: how good are their approximations of\nreality. The more precise the prediction, the lower the risk and the higher the\nrevenue. For the fledgling company Google, targeted advertisements are the\nembodiment of prediction products. However, as demonstrated by Zuboff,\nadvertising is far from being the end of the commodification of behavioral data.\n\n### Behavioral Market\n\n\u003cImage\n  alt={`Behavioral Market`}\n  src={`/images/surveillance-capitalism-overview/market.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nPrediction products after being fabricated by machine intelligence from massive\ncollections of behavioral surplus are then sold on a new kind of market: the\nbehavioral futures market. The market exchanges exclusively the knowledge of\nfuture behaviors of consumers. Although for most of the history of surveillance\ncapitalism, the dominant players of this new marketplace are advertisers, there\nis no reason why such markets are limited to this particular group.\n\nThe scope of behavioral futures markets has expanded throughout the advance of\nsurveillance capitalism in modern society, both in terms of potential customers\nand the variety of traded products: once confined to the online targeted\nadvertisement services, products of surveillance capitalists now may comprise\noffline predictions of users locations, emotions and actions, automated tools\nthat generated those predictions, and ultimately, behavioral modification tools\nthat align user behavior to the business’s means of profit-making. While\nsurveillance capitalism is based on classical capitalism and shares many common\ndynamics in its commercialization, there are necessary distinctions between the\ntwo that are worth highlighting.\n\nThe classical producer-consumer relationship of capitalism is starkly different\nfrom this freshly formed variance of it. On one hand, classical capitalism\nallows for constructive relations between the manufacturers and the consumers,\nin which the former creates supply and the latter induces demand. Manufacturers\nbase their course of actions on the state of the consumer market, adjusting\nproduct price, quality and capacity of their factories accordingly while for\nmost consumers, purchase decisions are based on the final price tags, affected\nprimarily by the original prices set by manufacturers.\n\nIn contrast, surveillance capitalism relationships with consumers - the users\nof the services - are exploitative rather than constructive. The consumers of\ndigital services have little to no influence on the operations of these\nservices. More and more of our online activities are accompanied by machine\nintelligence beyond our understanding. In fact, they have become behavioral\nmodification tools that are purposely designed to herd consumers like sheep to\nareas of data extraction. For example, Youtube video recommendation algorithms\nare programmed to maximize user on-site time rather than satisfying user needs\n(@bishopAnxietyPanicSelfoptimization2018). Another example is the clips sharing platform TikTok\nwith its personalized machine learning contents that keep young users hooked for\nhours (@andersonGettingAcquaintedSocial2020). Essentially, surveillance capitalists are\ntrying to automate consumers' behaviors, stripping their decision rights.\nConsumers on the other hand, have little to no power over their operations.\ntransformative effects on uncontrolled advancement of surveillance capitalism\nwill be discussed in detail in the next section.\n\nThis void of power over our own digital experience is what made the behavioral\nvalue reinvestment loop to run smoothly and the manufacture of prediction\nproducts run efficiently. Opposite to information capitalism, the services\nprovided by surveillance capitalists are nothing but hooks that lure users into\nconvenient areas of extraction. We are far from being the end consumer of\nsurveillance capitalism, in reality, we are on the opposite ends: the raw\nmaterials, objects of an inescapable system of continuous extraction.\n\n## Instrumentarian Power\n\n\u003cImage\n  alt={`Behavioral automation`}\n  src={`/images/surveillance-capitalism-overview/automated.png`}\n  width={1280}\n  height={720}\n  priority\n/\u003e\n\nCompetition in any capitalistic economic system drives the innovation of the\nmeans of production. However, in future rendition of surveillance capitalism,\ninnovations may not be required to equal more efficient manufacturing tools and\nextraction. Zuboff suspected that future surveillance capitalists could discover\nthat the best way to maximize their competitive advantages is to automate our\nbehaviors directly. Rather than produce more accurate algorithms and better\ntools of extractions, they may modify user behaviors and align them according to\ntheir customers' needs instead, maximizing the effectiveness of their no longer\nprediction product but behavioral modifications. As portrayed in her words:\n\n\u003e \" With this reorientation from knowledge to power, it is no longer enough to\n\u003e automate information flows about us; the goal now is to automate\n\u003e us.\"(@shoshanazuboffAgeSurveillanceCapitalism2019)\n\nThis realization among future surveillance capitalists might mark the birth of a\nnew species of power: instrumentarianism. The means of manufacture in\nsurveillance capitalism is now replaced by means of behavioral modification.\nPlayers of the system are now stuck in a continuous loop of intensification of\nthe mean behavioral controls, enjoying the gathering might of instrumentarian\npower that these means endowed.\n\nMoreover, the means of behavioral modification may not be limited to the digital\nworld. Competitive dynamics might nudge the expansion of behavioral futures\nmarkets beyond the digital sphere and into the physical world. The same\nfoundational mechanism used to lure and guide your online activities and\ndecisions such as liking posts, picking a product in an online webstore and\nwatching a particular Youtube video, can be repurposed to physically modifying\nyour behavior in the real world. For example Pokemon Go was Google's first\npublicly known experiment of physical behavioral modification in the real world\n(@shoshanazuboffAgeSurveillanceCapitalism2019). The viral phenomenon attracts millions of users across\nthe globe and becomes a tremendous financial success for Niantic Lab -\nsurprising to most, is an internal startup at Google - but most importantly for\nGoogle, it is a proof that such expansion of surveillance capitalism into the\nmarket of real-world behavioral modification is possible.\n\n## Conclusion\n\nIn the essay, I proposed a framework for exploration of surveillance capitalism\nand its relevant discussions. Starting from the fundamental operations of\nextraction and manufacture, we explored the concept of behavioral surplus and\nthe cycle that generates them: the behavioral reinvestment cycle. Then, we\nwitnessed how the inventor and first partitioner of surveillance capitalism:\nGoogle, came up with the solution to the financial problem they faced and the\neventual logical steps that they took to reach the invention of surveillance\ncapitalism. We also explored how different aspects of surveillance capitalists\nare protected and obfuscated and its nature as a man made creation. Finally we\nmoved on to the discussion of the commercial aspect of surveillance capitalism:\nprediction products and its market for exchange and consumption. We end our\nessay with a small discussion of the advancement of surveillance capitalism and\nits elevation from prediction products to behavioral modification as the primary\nmeans of production.\n\n## Reference\n","code":"var Component=(()=\u003e{var h=Object.create;var r=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var u=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var p=(t,a)=\u003e()=\u003e(a||t((a={exports:{}}).exports,a),a.exports),g=(t,a)=\u003e{for(var o in a)r(t,o,{get:a[o],enumerable:!0})},s=(t,a,o,n)=\u003e{if(a\u0026\u0026typeof a==\"object\"||typeof a==\"function\")for(let i of u(a))!m.call(t,i)\u0026\u0026i!==o\u0026\u0026r(t,i,{get:()=\u003ea[i],enumerable:!(n=d(a,i))||n.enumerable});return t};var b=(t,a,o)=\u003e(o=t!=null?h(f(t)):{},s(a||!t||!t.__esModule?r(o,\"default\",{value:t,enumerable:!0}):o,t)),v=t=\u003es(r({},\"__esModule\",{value:!0}),t);var l=p((G,c)=\u003e{c.exports=_jsx_runtime});var T={};g(T,{default:()=\u003ek,frontmatter:()=\u003ey});var e=b(l()),y={title:\"Surveillance Capitalism: An Overview\",publishedAt:\"2021-06-07\",summary:\"An overview of Shoshana Zuboff's Surveillance Capitalism.\",image:\"/images/surveillance-capitalism-overview/banner.png\"};function w(t={}){let{wrapper:a}=t.components||{};return a?(0,e.jsx)(a,Object.assign({},t,{children:(0,e.jsx)(o,{})})):o();function o(){let n=Object.assign({p:\"p\",em:\"em\",a:\"a\",h2:\"h2\",span:\"span\",sup:\"sup\",blockquote:\"blockquote\",ul:\"ul\",li:\"li\",h3:\"h3\",h4:\"h4\",section:\"section\",ol:\"ol\"},t.components),{Image:i}=n;return i||x(\"Image\",!0,\"8:1-14:3\"),(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(i,{alt:\"Surveillance Capitalism: An Overview\",src:\"/images/surveillance-capitalism-overview/banner.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsxs)(n.em,{children:[\"This was my final essay of CS-E5480: Digital Ethics D. \",(0,e.jsx)(n.a,{href:\"/static/surveillance-capitalism-overview.pdf\",children:\"PDF\"})]})}),`\n`,(0,e.jsxs)(n.h2,{id:\"introduction\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#introduction\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Introduction\"]}),`\n`,(0,e.jsx)(n.p,{children:`The 21st century witnessed the rapid digital transformation of the political,\nsocioeconomic landscape made possible by the internet. Digital technology was\nadvancing at a pace no one had expected, engendered waves of transformation\nacross multiple industries. As the burning flame of industrial innovation slowly\ndied out, the imminent information revolution was on the horizon, waiting to be\nset ablaze.`}),`\n`,(0,e.jsx)(n.p,{children:`The first decade was remembered as the rise of the first tech companies: Google,\nApple and Microsoft all experienced unprecedented growth during the period.\nThese accomplishments were celebrated globally, mostly in the US, as new\nconsumer products and digital services bring many conveniences and life\nimprovements. Little do we know that during the same period, a group of\nindividuals had invented an exploitative totalitarian form of capitalism, an\nunprecedented event of the digital transformation. Years later did the world\nstart to realize the nature of these big tech companies and the practices they\nemployed. Many research papers were published to address antitrust laws and\nmonopolistic practices of these companies but little addressed the fundamental\neconomic systems that comprise all their operations. Zuboff was first to realize\nand coined the term \"surveillance capitalism\" to characterize this rogue\neconomic system. This essay aims to provide an overview of the foundation of\nsurveillance capitalism, its components, operations, consequences, and a simple\npath for exploration of the topic.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"outline\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#outline\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Outline\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`Surveillance capitalism as a general economical concept was introduced in \"A\ndigital declaration\" by Shoshana Zuboff in 2014. The paper marks the first\npublication on this mutation of capitalism and sparks many discussions on many\ntechnical practices of Big Tech companies such as Google, Facebook, and\nMicrosoft. Subsequent scholarly articles further built upon the definition that\nhad already been laid out in her original paper. In 2019, a major work on\nsurveillance capitalism was published: \"The Age of Surveillance Capitalism: The\nFight for a Human Future at the New Frontier of Power\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),`, in which, she\nsummarized:`]}),`\n`,(0,e.jsxs)(n.blockquote,{children:[`\n`,(0,e.jsxs)(n.p,{children:[`\"Surveillance capitalism is best described as a coup from above, not an\noverthrow of the state but rather an overthrow of the people's sovereignty and a\nprominent force in the perilous drift towards democratic deconsolidation that\nnow threatens Western liberal democracies.\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-2\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})})]}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:`These ominous consequences of surveillance capitalism call for a coherent\nethical framework in an attempt to encapsulate all of its complications. In this\nessay, I suggest one such framework, albeit simplified, which consists of three\ndistinct but interconnected operations that constitute the primary behaviors\nobserved in surveillance capitalism:`}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:`The mining of \"behavioral surplus\" from user activities and experiences.\n(extraction)`}),`\n`,(0,e.jsx)(n.li,{children:`The feeding of behavioral data into advanced analytical processes\n(\"machine intelligence\") to produce \"prediction products\" (manufacture)`}),`\n`,(0,e.jsx)(n.li,{children:`The exchange of prediction products on \"behavioral futures markets\"\n(commercialization)`}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:`Concrete examples will be shown in subsequent sections, where the three primary\noperations of surveillance capitalism are laid out and explored in detail.\nHowever, it is necessary that some fundamental theoretical concepts are clearly\nunderstood beforehand.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"extraction-and-manufacture\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#extraction-and-manufacture\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Extraction and Manufacture\"]}),`\n`,(0,e.jsxs)(n.h3,{id:\"machine-intelligence\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#machine-intelligence\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Machine Intelligence\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`First, to understand the extraction and manufacturing process of surveillance\ncapitalism, it is necessary that a frequently used term is clearly understood\nbeforehand: machine intelligence. The term is used frequently in Zuboff\\u2019s \"Age\nof surveillance capitalism\" as a means to bypass the technicality of analytical\npractices`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-3\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),`. In summary, machine intelligence is a\ngeneralization of different specialized computational tools that are used for\ndata analysis and manufacture of data-based products. It is used frequently as\nan umbrella phrase that covers complex computational methods employed by\nsurveillance capitalists such as artificial intelligence, predictive analytics,\nand machine learning, allowing for easy reference in other areas of science. Its\nrole is to help concentrate our attention on the more important issues of\nsurveillance capitalism, decentering our focus from the technology it employs to\nits objectives instead.`]}),`\n`,(0,e.jsxs)(n.h3,{id:\"the-behavioral-value-reinvestment-cycle\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#the-behavioral-value-reinvestment-cycle\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"The Behavioral Value Reinvestment Cycle\"]}),`\n`,(0,e.jsx)(i,{alt:\"The Behavioral Value Reinvestment Cycle\",src:\"/images/surveillance-capitalism-overview/cycle.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`A fundamental component of surveillance capitalism is the loop of behavioral\ndata collection, analysis, services improvements and increased user activities -\nthe behavioral value reinvestment cycle. It came to existence during the early\ninvention of surveillance capitalism at Google, when engineers began to apply\nmachine intelligence to massive collections of user\\u2019s past queries. The outputs\nof these analyses were then translated to improvements of the user experiences:\nbetter detection of typos, better accuracy and more relevance query\nresults/suggestions. In other words, the value created was reinvested directly\ninto improving the user experience, hence the name. These enhancements in turn\nattract more users onto the platform, producing even more behavioral data for\nanalysis. This self-improving mechanism is so effective that only 1 year since\nGoogle's establishment, more than seven million user requests were conducted on\nits search engine each day. Note that user data was provided at no cost but so\nare the enhancements of the platform\\u2019s services for users.`}),`\n`,(0,e.jsx)(n.p,{children:`Before moving on, there are some misconceptions that need to be pointed out.\nSince there is no economic exchange, no price and no profit, it is inaccurate to\nthink of Google\\u2019s users as the customers. There are also no wages involved or\nthe provision of the means of production: users are not paid for the data they\nproduced nor do they operate the process of web crawling or its enhancements.\nConsequently, it is also wrong to think of them as workers of the cycle.\nFinally, there is also a common rhetoric that the user is the \"product\" of the\nsystem. However, this is also misleading as many aspects of being the \"product\"\nare missing and such expressions further confuse the issue rather than\nclarifying it.`}),`\n`,(0,e.jsx)(n.p,{children:`The cycle was once all there is to the operations of Google - the first\npractitioner of surveillance capitalism. While being different to previous\ncustomer-manufacture relationships by embodying a new mechanism for improving\nproducts and enlarging user base, the behavioral reinvestment cycle is not yet\ncapitalism, at least in its current stage.`}),`\n`,(0,e.jsx)(i,{alt:\"Google HQ\",src:\"/images/surveillance-capitalism-overview/google-hq.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`During the early days of Google, there was the major issue of converting the\nservice usages to revenues: charging the user for their searches seemed\nfinancially risky and counterproductive; monetizing the searches seemed to be a\ndangerous precedent as much of Google's indexed information is taken without\npayment from the contents\\u2019 hosts. The cycle, while possessing the capacity of\nproducing advanced technologies, is financially unsustainable and failed as a\nfunctional business model. For Google, providing advertisement service was the\nonly viable solution.`}),`\n`,(0,e.jsxs)(n.p,{children:[`The decision of incorporating advertisements on the company website faced much\nopposition at the start, mostly from the company's engineers and analysts. Many\nengineers of Google's AdWords team displayed antipathy toward ads, fearing\nuncontrolled bias towards advertisers could steer the company away from user\\u2019s\nneed and degrading searches\\u2019 integrity`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-2\",id:\"user-content-fnref-2\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"2\"})}),`. However,\nfinancial pressure from the fallout of the \"dotcom bubble\" and intense market\ncompetition in the early 2000s eventually surmounted ethical ideals. To make\nmore money, it was proposed that advertisements should be automatically targeted\nto specific consumers, simplifying the whole process of picking which keywords\ninciting which ads for advertisers wanting to use Google online advertising\nplatform. Finding the solution to this problem eventually led to Google\\u2019s\ndiscovery of the centerpiece of surveillance capitalism: the behavioral surplus.`]}),`\n`,(0,e.jsxs)(n.h3,{id:\"behavioral-surplus\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#behavioral-surplus\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Behavioral Surplus\"]}),`\n`,(0,e.jsx)(i,{alt:\"The discovery of behavioral surplus\",src:\"/images/surveillance-capitalism-overview/surplus.png\",width:1280,height:1e3,priority:!0}),`\n`,(0,e.jsxs)(n.p,{children:[`The behavior surplus can be described as by-products formed from user digital\nactivities, usually existing in the form of behavioral patterns in collection of\nuser data, readily extracted and transformed into prediction products. It is a\ncomponent of the behavioral value reinvestment cycle, the \"data exhaust\"\nproduced during user digital activities and their analysis`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-3\",id:\"user-content-fnref-3\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"3\"})}),`\n. For example, the innocent act of searching the web for a keyword on Google\nproduces a wake of collateral data such as search counts, phrasing, tonations,\nclick patterns, dwell times and geographic locations. These excess behavioral\ndata were once thought to be \"exhaust material\" and devoid of meaningful values,\nthus, were either cached in massive data stores as backups or discarded\nentirely. For instance, Google stores user queries results for archiving\npurposes in its early days of operation without much knowledge of its hidden\npredictive values.`]}),`\n`,(0,e.jsxs)(n.p,{children:[`Later analysis of such seemingly unrelated accidental data in massive quantities\nor \"data mining\" reveals behavioral patterns representing sensitive aspects of\nhuman behaviors such as emotions, moods, intentions and needs. Such insights\ngive Google a powerful competitive advantage over its competitors in the ads\nservices provider market. For example, a rival search startup Overture had\ndeveloped an online auction system to address the scaling problem of online\ntargeted advertisement. Compelled, Google also developed a similar auction\nsystem but added a transformational functionality: probabilistic modeling of\nuser\\u2019s clicks on ads. The model produced a numeric representation that can be\nused to compare the effectiveness of advertiser\\u2019s ads on a particular user, not\nonly maximizing specificity and accuracy but also the number of advertisers\nGoogle's can handle at any given time by minimizing. Eventually, Google\nsucceeded and held the monopoly over web searching, eliminating many companies\nin the same service space during the process.`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-4\",id:\"user-content-fnref-4\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"4\"})})]}),`\n`,(0,e.jsx)(n.p,{children:`The discovery of behavioral surplus and its capability of behavioral prediction\nmarked the shift of priorities for Google\\u2019s investment strategy. Under the hood,\nthe behavioral reinvestment cycle was rapidly subordinated by a much more\ncomplex system of operations unbeknown to users. While some of the data relevant\nto the improvement of user services will still be reinvested for the benefit of\nthe consumer, the focus was now placed on the maximization of extracted\nbehavioral data and development of machine intelligence and operations that\nderive values from these data. The purpose of improving services slowly\ndescended to keeping users engaged and the platform reliable for the intention\nof extraction. For Google, it is keeping users reliant on Google for online\nbrowsing and analyzing their queries for better targeted ads. Note that targeted\nadvertisement is just one of the derivatives of prediction products made\npossible by surveillance capitalism and not the only source of values for\nsurveillance capitalists.`}),`\n`,(0,e.jsx)(n.p,{children:`The discovery had also induced another change in corporate mindset at Google:\nthe company is now compelled to actively hunt for sources of behavioral surplus\nand better tools of extraction rather than waiting for accidental patterns\nemerging from user activities. This was characterized by Zuboff as the\nextraction imperative, in contrast to the production imperative of industrial\ncapitalism. An example is Google\\u2019s \"senseless\" $1.65 billion acquisition of\nYoutube at a time this video-sharing startup was ridden with copyright\ninfringement lawsuits and a year of profitless operation. Another example is\nFacebook\\u2019s \"reckless\" purchase of overvalued unprofitable startups such as the\nvirtual reality company Oculus ($2 billion) and the messaging platform WhatApps\n($19 billion). Only years later was it known that these seemingly ludicrous\nbusiness decisions were deliberately aimed at acquiring potential sources of\nbehavioral surplus that evidently, had brought tremendous amounts of capital for\nthese first movers of surveillance capitalism.`}),`\n`,(0,e.jsxs)(n.h3,{id:\"the-moat\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#the-moat\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"The Moat\"]}),`\n`,(0,e.jsx)(i,{alt:\"The discovery of behavioral surplus\",src:\"/images/surveillance-capitalism-overview/moat.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsxs)(n.p,{children:['In the discussion of \"The moat around the castle\"',(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-4\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),` Zuboff\nlaid out three main paths of exploration that go into detail how socio-political\ncircumstances and deliberate practices of surveillance capitalism obfuscate its\nemployers\\u2019 practices and legitimizing their exploitative operations. These\nincludes: (1) the pursuit and defense of corporate freedom and operational\nrights in unregulated space; (2) the sudden federal interests in the\ncapabilities of behavioral surplus analytics after 9/11; and (3) the\nconstruction of fortifications in politic and academia to protect and deflect\nscrutiny of its practices.`]}),`\n`,(0,e.jsxs)(n.h4,{id:\"right-to-unregulated-space\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#right-to-unregulated-space\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Right to Unregulated Space\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`The founders at Google had instituted a corporate structure that allowed the two\nopposites to coexist: total controls over the market sphere and the pursuit of\nfreedom in the public sphere. Such freedom was made possible by the unregulated\nnature of cyberspace, mostly due to its novelty as an area of business\nactivities and economic operations. The cyberspace was characterized by Eric\nSchmidt and Jared Cohen in the book \"The New Digital Age\", as the world's\n\"largest ungovern space\" and truly unbound by \"terrestrial laws\" and\njurisdictions`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-5\",id:\"user-content-fnref-5\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"5\"})}),`. The lack of political institutions is what\nmade cyberspace attractive to surveillance capitalists: a frictionless space\nwhere behavioral surplus extraction and manufacturing operations are done\nsmoothly and efficiently without any socio-political hindrances. Such policy\ngaps were a direct transformation of the speed gaps between democratic\ninstitutions and bigtech corporations. As admitted by Schmidt in his elaboration\nof the 2011 senate testimony, the same antidemocratic measure of leveraging\nspeed \"also work for Google\" and described as:`]}),`\n`,(0,e.jsxs)(n.blockquote,{children:[`\n`,(0,e.jsx)(n.p,{children:`\"This is an Andy Grove (Intel former CEO) formula.... \"High tech runs\nthree-times faster than normal businesses. And the government runs three-times\nslower than normal businesses. So we have a nine-times gap.... And so what you\nwant to do is you want to make sure that the government does not get in the way\nand slow things down\"`}),`\n`]}),`\n`,(0,e.jsxs)(n.h4,{id:\"a-historical-circumstance\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#a-historical-circumstance\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"A Historical Circumstance\"]}),`\n`,(0,e.jsx)(n.p,{children:`The 9/11 terror attacks had caused significant mentality changes among\ngovernment officials and the general sentiments toward public surveillance. The\nhistorical circumstance has united the causes of public intelligence agencies\nand the early surveillance capitalist Google, producing a unique historical\ndeformity: surveillance exceptionalism.`}),`\n`,(0,e.jsxs)(n.p,{children:[`The terror attacks had shifted the perception of the federal government on the\npractices of online surveillance: from being operations in violation of user\nprivacy to mission necessities critical to the safety of the public. Both\ninstitutions coveted certainty of user behaviors and were motivated to fulfill\nthat craving in their respective domains at any cost. The circumstances lent\nsurveillance capitalism a shelter from scrutiny by slowly legitimizing its\noperations in the political sphere. Intelligence agencies were now motivated to\nreplicate Google\\u2019s means of extraction and manufacture, spreading surveillance\ncapitalism\\u2019s ideologies to other sectors of power in society. For example, in\n2006, General Keith Alexander outlined his vision for a search tool called\nICREACH that, quoted: \"allow unprecedented volumes of metadata to be shared and\nanalyzed across the many agencies in the Intelligence\nCommunity\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-6\",id:\"user-content-fnref-6\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"6\"})}),`. In 2007 two NSA analysts wrote an\ninternal training manual on how to find information on the internet`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-7\",id:\"user-content-fnref-7\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"7\"})}),`. Such craving slowly translated to reliance, as the\ngovernment grew dependent on Silicon Valley to defend security threats looming\nin cyberspace, deepening the relationship between governments and surveillance\ncapitalists.`]}),`\n`,(0,e.jsxs)(n.h4,{id:\"fortification\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#fortification\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Fortification\"]}),`\n`,(0,e.jsxs)(n.p,{children:[`The fortification strategies employed by surveillance capitalists, to my\nknowledge, consist of four main demonstrative operations: providing competitive\nadvantage in electoral politics, personnel migration to and from government\nsectors, aggressive lobbying and manipulating public perception by influencing\ncultural conversation and academic publications. For example, the 2008 Obama\npresidential campaign had Eric Schmidt - the sitting CEO of Google - as one of\nthe main directors, in charge of implementing state-of-the-art data strategies\nthat have the potential to shadow traditional political campaigning with the\nscience of behavioral prediction`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-8\",id:\"user-content-fnref-8\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"8\"})}),`. Personnel\nmigration can be seen frequently through the years of operation at Google: the\nGoogle Transparency Project found that by April 2016, 61 individuals had\nmigrated from the Google Sphere (company employees plus affiliates and\nlaw/lobbying firms) to the government and over 197 government officials had\nmoved back`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-9\",id:\"user-content-fnref-9\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"9\"})}),`. Lobbying is a common practice for Google: in\n2014, more than $17 million was spent on lobbying outlay and in 2018, that\nnumber rose to more than $18 million`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-9\",id:\"user-content-fnref-9-2\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"9\"})}),`. To obfuscate its\npractices, Google exercises information manipulation by means of financial\npressure to influence academic research and steering public opinion. Since 2009,\nit has been reported that Google had deliberately sought out and funded\nuniversity professors for policy papers in agreement with Google's positions.`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-10\",id:\"user-content-fnref-10\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"10\"})})]}),`\n`,(0,e.jsxs)(n.h3,{id:\"a-human-invention\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#a-human-invention\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"A Human Invention\"]}),`\n`,(0,e.jsx)(i,{alt:\"Human invention\",src:\"/images/surveillance-capitalism-overview/invention.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`It is important to emphasize that surveillance capitalism is an intentional\ncreation, an invention made at a specific time and at a specific place by a\ngroup of individuals. It is not an inevitable result of the digital\ntransformation, nor an expression of information capitalism. It was deliberately\nconstructed to solve a business problem at a particular moment in history. If\nthere was no recession nor the dotcom crash, or the people in charge making the\ndecision that they had made, the fire might not have started and surveillance\ncapitalism might have not come to existence.`}),`\n`,(0,e.jsxs)(n.p,{children:[`Many elements of online surveillance predated the creation of surveillance. For\nexample, \"cookies\" or small pieces of data stored on the user's computer by the\nweb browser that allow websites to remember user information and activities, had\nalready been introduced in 1994 by Netscape`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-11\",id:\"user-content-fnref-11\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"11\"})}),`. Other\nsimilar online browsing trackers and surveillance tools such as \"web beacon\" or\n\"web bugs\" were well-known among experts during the late 1990s`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-12\",id:\"user-content-fnref-12\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"12\"})}),`. However, it was Google that integrated a wide range of\nonline surveillance mechanisms, from cookies to predictive analytics that allow\nfor the institution of a new logic of accumulation by means of data extraction\nand analysis, establishing a new market for commercialized prediction products\nwhere customers are businesses, not consumers.`]}),`\n`,(0,e.jsxs)(n.h2,{id:\"commercialization\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#commercialization\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Commercialization\"]}),`\n`,(0,e.jsxs)(n.h3,{id:\"prediction-product\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#prediction-product\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Prediction Product\"]}),`\n`,(0,e.jsx)(i,{alt:\"Prediction product\",src:\"/images/surveillance-capitalism-overview/product.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`Surveillance capitalism is a derivative of capitalism and thus the exchange of\nproducts among its actors is one of its fundamental activities. Differ from\npopular industrial capitalism where commodities are manufactured goods traded on\nthe open market, surveillance capitalism goods are prediction products that\nforecast future behaviors of users. These include, but not limited to: thoughts,\nactions, emotions, moods, desires, physical needs, psychological needs,\nshort-term intentions and possibly long-term intentions, given sufficiently\npowerful behavioral data. It is the nature of prediction products that explains\nwhy Google constantly distant themselves from the notion of selling personal\ndata. Google does not sell the raw materials, they sell the predictions. The\nclaim of privacy purity is just a superficial excuse that conceal the backstage\noperations of surveillance capitalism it employs.`}),`\n`,(0,e.jsx)(n.p,{children:`Prediction products reduce uncertainty in their customers' operations, advising\nthem where and when to allocate resources. The quality of prediction products is\na direct translation of its accuracy: how good are their approximations of\nreality. The more precise the prediction, the lower the risk and the higher the\nrevenue. For the fledgling company Google, targeted advertisements are the\nembodiment of prediction products. However, as demonstrated by Zuboff,\nadvertising is far from being the end of the commodification of behavioral data.`}),`\n`,(0,e.jsxs)(n.h3,{id:\"behavioral-market\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#behavioral-market\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Behavioral Market\"]}),`\n`,(0,e.jsx)(i,{alt:\"Behavioral Market\",src:\"/images/surveillance-capitalism-overview/market.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`Prediction products after being fabricated by machine intelligence from massive\ncollections of behavioral surplus are then sold on a new kind of market: the\nbehavioral futures market. The market exchanges exclusively the knowledge of\nfuture behaviors of consumers. Although for most of the history of surveillance\ncapitalism, the dominant players of this new marketplace are advertisers, there\nis no reason why such markets are limited to this particular group.`}),`\n`,(0,e.jsx)(n.p,{children:`The scope of behavioral futures markets has expanded throughout the advance of\nsurveillance capitalism in modern society, both in terms of potential customers\nand the variety of traded products: once confined to the online targeted\nadvertisement services, products of surveillance capitalists now may comprise\noffline predictions of users locations, emotions and actions, automated tools\nthat generated those predictions, and ultimately, behavioral modification tools\nthat align user behavior to the business\\u2019s means of profit-making. While\nsurveillance capitalism is based on classical capitalism and shares many common\ndynamics in its commercialization, there are necessary distinctions between the\ntwo that are worth highlighting.`}),`\n`,(0,e.jsx)(n.p,{children:`The classical producer-consumer relationship of capitalism is starkly different\nfrom this freshly formed variance of it. On one hand, classical capitalism\nallows for constructive relations between the manufacturers and the consumers,\nin which the former creates supply and the latter induces demand. Manufacturers\nbase their course of actions on the state of the consumer market, adjusting\nproduct price, quality and capacity of their factories accordingly while for\nmost consumers, purchase decisions are based on the final price tags, affected\nprimarily by the original prices set by manufacturers.`}),`\n`,(0,e.jsxs)(n.p,{children:[`In contrast, surveillance capitalism relationships with consumers - the users\nof the services - are exploitative rather than constructive. The consumers of\ndigital services have little to no influence on the operations of these\nservices. More and more of our online activities are accompanied by machine\nintelligence beyond our understanding. In fact, they have become behavioral\nmodification tools that are purposely designed to herd consumers like sheep to\nareas of data extraction. For example, Youtube video recommendation algorithms\nare programmed to maximize user on-site time rather than satisfying user needs`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-13\",id:\"user-content-fnref-13\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"13\"})}),`. Another example is the clips sharing platform TikTok\nwith its personalized machine learning contents that keep young users hooked for\nhours`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-14\",id:\"user-content-fnref-14\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"14\"})}),`. Essentially, surveillance capitalists are\ntrying to automate consumers' behaviors, stripping their decision rights.\nConsumers on the other hand, have little to no power over their operations.\ntransformative effects on uncontrolled advancement of surveillance capitalism\nwill be discussed in detail in the next section.`]}),`\n`,(0,e.jsx)(n.p,{children:`This void of power over our own digital experience is what made the behavioral\nvalue reinvestment loop to run smoothly and the manufacture of prediction\nproducts run efficiently. Opposite to information capitalism, the services\nprovided by surveillance capitalists are nothing but hooks that lure users into\nconvenient areas of extraction. We are far from being the end consumer of\nsurveillance capitalism, in reality, we are on the opposite ends: the raw\nmaterials, objects of an inescapable system of continuous extraction.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"instrumentarian-power\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#instrumentarian-power\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Instrumentarian Power\"]}),`\n`,(0,e.jsx)(i,{alt:\"Behavioral automation\",src:\"/images/surveillance-capitalism-overview/automated.png\",width:1280,height:720,priority:!0}),`\n`,(0,e.jsx)(n.p,{children:`Competition in any capitalistic economic system drives the innovation of the\nmeans of production. However, in future rendition of surveillance capitalism,\ninnovations may not be required to equal more efficient manufacturing tools and\nextraction. Zuboff suspected that future surveillance capitalists could discover\nthat the best way to maximize their competitive advantages is to automate our\nbehaviors directly. Rather than produce more accurate algorithms and better\ntools of extractions, they may modify user behaviors and align them according to\ntheir customers' needs instead, maximizing the effectiveness of their no longer\nprediction product but behavioral modifications. As portrayed in her words:`}),`\n`,(0,e.jsxs)(n.blockquote,{children:[`\n`,(0,e.jsxs)(n.p,{children:[`\" With this reorientation from knowledge to power, it is no longer enough to\nautomate information flows about us; the goal now is to automate\nus.\"`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-5\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})})]}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:`This realization among future surveillance capitalists might mark the birth of a\nnew species of power: instrumentarianism. The means of manufacture in\nsurveillance capitalism is now replaced by means of behavioral modification.\nPlayers of the system are now stuck in a continuous loop of intensification of\nthe mean behavioral controls, enjoying the gathering might of instrumentarian\npower that these means endowed.`}),`\n`,(0,e.jsxs)(n.p,{children:[`Moreover, the means of behavioral modification may not be limited to the digital\nworld. Competitive dynamics might nudge the expansion of behavioral futures\nmarkets beyond the digital sphere and into the physical world. The same\nfoundational mechanism used to lure and guide your online activities and\ndecisions such as liking posts, picking a product in an online webstore and\nwatching a particular Youtube video, can be repurposed to physically modifying\nyour behavior in the real world. For example Pokemon Go was Google's first\npublicly known experiment of physical behavioral modification in the real world`,(0,e.jsx)(n.sup,{children:(0,e.jsx)(n.a,{href:\"#user-content-fn-1\",id:\"user-content-fnref-1-6\",\"data-footnote-ref\":!0,\"aria-describedby\":\"footnote-label\",children:\"1\"})}),`. The viral phenomenon attracts millions of users across\nthe globe and becomes a tremendous financial success for Niantic Lab -\nsurprising to most, is an internal startup at Google - but most importantly for\nGoogle, it is a proof that such expansion of surveillance capitalism into the\nmarket of real-world behavioral modification is possible.`]}),`\n`,(0,e.jsxs)(n.h2,{id:\"conclusion\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#conclusion\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Conclusion\"]}),`\n`,(0,e.jsx)(n.p,{children:`In the essay, I proposed a framework for exploration of surveillance capitalism\nand its relevant discussions. Starting from the fundamental operations of\nextraction and manufacture, we explored the concept of behavioral surplus and\nthe cycle that generates them: the behavioral reinvestment cycle. Then, we\nwitnessed how the inventor and first partitioner of surveillance capitalism:\nGoogle, came up with the solution to the financial problem they faced and the\neventual logical steps that they took to reach the invention of surveillance\ncapitalism. We also explored how different aspects of surveillance capitalists\nare protected and obfuscated and its nature as a man made creation. Finally we\nmoved on to the discussion of the commercial aspect of surveillance capitalism:\nprediction products and its market for exchange and consumption. We end our\nessay with a small discussion of the advancement of surveillance capitalism and\nits elevation from prediction products to behavioral modification as the primary\nmeans of production.`}),`\n`,(0,e.jsxs)(n.h2,{id:\"reference\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#reference\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Reference\"]}),`\n`,(0,e.jsxs)(n.section,{\"data-footnotes\":!0,className:\"footnotes\",children:[(0,e.jsxs)(n.h2,{id:\"footnote-label\",className:\"sr-only\",children:[(0,e.jsx)(n.a,{className:\"anchor\",href:\"#footnote-label\",children:(0,e.jsx)(n.span,{className:\"icon icon-link\"})}),\"Footnotes\"]}),`\n`,(0,e.jsxs)(n.ol,{children:[`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-1\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Shoshana Zuboff. The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power. PublicAffairs; 2019.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-1\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-2\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"2\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-3\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"3\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-4\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"4\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-5\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"5\"})]}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-1-6\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"6\"})]})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-2\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Brin S, Page L. The Anatomy of a Large-Scale Hypertextual Web Search Engine. Computer Networks and ISDN Systems [Internet]. 1998 Apr [cited 2022 May 13];30(1):107\\u201317. Available from: https://www.sciencedirect.com/science/article/pii/S016975529800110X\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-2\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-3\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Cukier K. Data, Data Everywhere. ECONOMIST [Internet]. [cited 2022 May 13];394(8671):3\\u20135. Available from: https://search.informit.org/doi/abs/10.3316/agispt.20100985\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-3\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-4\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Coy P. The Secret to Google\\u2019s Success. Business Week. 2006;17.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-4\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-5\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Eric Schmidt, Jared Cohen. The New Digital Age: Transforming Nations, Businesses, and Our Lives. Knopf Doubleday Publishing Group; 2013.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-5\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-6\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Gallagher R. The Surveillance Engine: How the NSA Built Its Own Secret Google. The Intercept. 2014;25.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-6\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-7\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Bishop B. NSA Reveals Its Internet Search Tricks in the Recently Declassified \\u201CUntangling the Web\\u201D [Internet]. The Verge. 2013 [cited 2022 May 13]. Available from: https://www.theverge.com/2013/5/8/4313524/nsa-reveals-its-internet-search-tricks-in-the-recently-declassified-untangling-the-web\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-7\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-8\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Eric Schmidt: Obama\\u2019s Chief Corporate Ally [Internet]. Tech Transparency Project. 2016 [cited 2022 May 13]. Available from: https://www.techtransparencyproject.org/articles/eric-schmidt-obamas-chief-corporate-ally\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-8\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-9\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Google Transparency Report [Internet]. [cited 2022 May 13]. Available from: https://transparencyreport.google.com/?hl=en\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-9\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"}),\" \",(0,e.jsxs)(n.a,{href:\"#user-content-fnref-9-2\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:[\"\\u21A9\",(0,e.jsx)(n.sup,{children:\"2\"})]})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-10\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Nicas BM and J. Paying Professors: Inside Google\\u2019s Academic Influence Campaign. Wall Street Journal [Internet]. 2017 Jul [cited 2022 May 13]; Available from: https://www.wsj.com/articles/paying-professors-inside-googles-academic-influence-campaign-1499785286\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-10\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-11\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Kristol DM. HTTP Cookies: Standards, Privacy, and Politics. ACM Transactions on Internet Technology [Internet]. 2001 Nov [cited 2022 May 13];1(2):151\\u201398. Available from: https://doi.org/10.1145/502152.502153\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-11\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-12\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Smith RM. The Web Bug Faq. Nov. 1999;11:4.\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-12\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-13\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Bishop S. Anxiety, Panic and Self-Optimization: Inequalities and the YouTube Algorithm. Convergence [Internet]. 2018 Feb [cited 2022 May 13];24(1):69\\u201384. Available from: https://doi.org/10.1177/1354856517736978\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-13\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{id:\"user-content-fn-14\",children:[`\n`,(0,e.jsxs)(n.p,{children:[`1. Anderson KE. Getting Acquainted with Social Networks and Apps: It Is Time to Talk about TikTok. Library Hi Tech News [Internet]. 2020 Jan [cited 2022 May 13];37(4):7\\u201312. Available from: https://doi.org/10.1108/LHTN-01-2020-0001\n `,(0,e.jsx)(n.a,{href:\"#user-content-fnref-14\",\"data-footnote-backref\":!0,className:\"data-footnote-backref\",\"aria-label\":\"Back to content\",children:\"\\u21A9\"})]}),`\n`]}),`\n`]}),`\n`]})]})}}var k=w;function x(t,a,o){throw new Error(\"Expected \"+(a?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\"+(o?\"\\nIt\\u2019s referenced in your code at `\"+o+\"` in `/home/phanthh/Development/--WEB/phanthh.github.io/data/_mdx_bundler_entry_point-cfe606d9-fa50-47a9-823d-742265e79957.mdx`\":\"\"))}return v(T);})();\n;return Component;"},"_id":"blog/surveillance-capitalism-overview.mdx","_raw":{"sourceFilePath":"blog/surveillance-capitalism-overview.mdx","sourceFileName":"surveillance-capitalism-overview.mdx","sourceFileDir":"blog","contentType":"mdx","flattenedPath":"blog/surveillance-capitalism-overview"},"type":"Blog","readingTime":{"text":"21 min read","minutes":20.365,"time":1221900,"words":4073},"wordCount":4075,"slug":"surveillance-capitalism-overview"}},"__N_SSG":true},"page":"/blog/[slug]","query":{"slug":"surveillance-capitalism-overview"},"buildId":"iFfwlBYB_AelDcwc8h405","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>